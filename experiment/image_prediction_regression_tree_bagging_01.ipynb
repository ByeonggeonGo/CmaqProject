{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import collections\n",
    "path = os.getcwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119, 64, 64, 4)\n"
     ]
    }
   ],
   "source": [
    "# In[] SMOKE-CMAQ\n",
    "# CMAQ 연평균 PM농도\n",
    "pm2_5 = np.array([])\n",
    "\n",
    "for i in range(1,120):\n",
    "    a = 'ACONC.' + str(i)\n",
    "    nc = Dataset(a, 'r')\n",
    "    pm2_5 = np.append(pm2_5, np.array([[[nc.variables['PM2_5']]]]))\n",
    "    \n",
    "pm2_5 = np.reshape(pm2_5, [119,82,67])\n",
    "pm2_5 = pm2_5[:,8:-10,2:-1]\n",
    "pm2_5 = np.reshape(pm2_5, [119,64,64]) # convolution 연산을 위해\n",
    "\n",
    "pm = pm2_5\n",
    "\n",
    "\n",
    "y1 = np.array([])\n",
    "y2 = np.array([])\n",
    "y3 = np.array([])\n",
    "y4 = np.array([])\n",
    "y5 = np.array([])\n",
    "y6 = np.array([])\n",
    "\n",
    "for i in range(1,120):\n",
    "    a = 'EMIS_AVG.' + str(i)\n",
    "    nc = Dataset(a, 'r')\n",
    "    y1 = np.append(y1, np.array([[[nc.variables['SO2']]]]))\n",
    "    y2 = np.append(y2, np.array([[[nc.variables['PM2_5']]]]))\n",
    "    y3 = np.append(y3, np.array([[[nc.variables['NOx']]]]))\n",
    "    y4 = np.append(y4, np.array([[[nc.variables['VOCs']]]]))\n",
    "    y5 = np.append(y5, np.array([[[nc.variables['NH3']]]]))\n",
    "    y6 = np.append(y6, np.array([[[nc.variables['CO']]]]))\n",
    "    \n",
    "y1 = np.reshape(y1, [119,82,67])\n",
    "y1 = y1[:,8:-10,2:-1]\n",
    "y1 = np.reshape(y1, [119,64,64])\n",
    "y1_max = np.max(y1)\n",
    "y1_min = np.min(y1)\n",
    "\n",
    "y2 = np.reshape(y2, [119,82,67])\n",
    "y2 = y2[:,8:-10,2:-1]\n",
    "y2 = np.reshape(y2, [119,64,64])\n",
    "y2_max = np.max(y2)\n",
    "y2_min = np.min(y2)\n",
    "\n",
    "y3 = np.reshape(y3, [119,82,67])\n",
    "y3 = y3[:,8:-10,2:-1]\n",
    "y3 = np.reshape(y3, [119,64,64])\n",
    "y3_max = np.max(y3)\n",
    "y3_min = np.min(y3)\n",
    "\n",
    "y4 = np.reshape(y4, [119,82,67])\n",
    "y4 = y4[:,8:-10,2:-1]\n",
    "y4 = np.reshape(y4, [119,64,64])\n",
    "y4_max = np.max(y4)\n",
    "y4_min = np.min(y4)\n",
    "\n",
    "y5 = np.reshape(y5, [119,82,67])\n",
    "y5 = y5[:,8:-10,2:-1]\n",
    "y5 = np.reshape(y5, [119,64,64])\n",
    "y5_max = np.max(y5)\n",
    "y5_min = np.min(y5)\n",
    "    \n",
    "y6 = np.reshape(y6, [119,82,67])\n",
    "y6 = y6[:,8:-10,2:-1]\n",
    "y6 = np.reshape(y6, [119,64,64])\n",
    "\n",
    "\n",
    "def pm_data():\n",
    "    a = np.concatenate((y3,y1,y4,y5), axis=0) # PM2.5, SO2, NH3\n",
    "    a = np.reshape(a,[4,119,64,64]) # data generation for CNN ??\n",
    "    a = np.transpose(a, (1,2,3,0)) # CNN 학습을 위한 순서변경\n",
    "    print(np.shape(a))\n",
    "    \n",
    "    y = pm\n",
    "    \n",
    "    y = np.reshape(y, [119,64,64,1]) # CNN output data\n",
    "    x_train = a[0:70]\n",
    "    y_train = y[0:70]\n",
    "    x_test = a[70:]\n",
    "    pm2_5 = y[70:]\n",
    "    return x_train, y_train, x_test, pm2_5, a, y\n",
    "\n",
    "\n",
    "pm_data1 = pm_data()\n",
    "x_train, y_train, x_test, pm2_5, a, y = pm_data1[0], pm_data1[1], pm_data1[2], pm_data1[3], pm_data1[4], pm_data1[5]#, pm_data1[6], pm_data1[7] \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 개별모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tree():\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth: float,\n",
    "        i_depth: float,\n",
    "        minimum_sample_leaf: float,\n",
    "        y_val: np.array,\n",
    "        x_val: np.array,\n",
    "        is_terminal: bool,\n",
    "\n",
    "        kernel_size: list,\n",
    "        kernel_n: int,\n",
    "\n",
    "        sample_ratio_by_tree: float,\n",
    "        weight: float,\n",
    "\n",
    "        input_shape: list,\n",
    "        kernel_cords = None\n",
    "    ):\n",
    "        self.max_depth = max_depth\n",
    "        self.minimum_sample_leaf = minimum_sample_leaf\n",
    "        self.i_depth = i_depth\n",
    "        self.is_terminal = is_terminal\n",
    "\n",
    "        self.y_val = y_val\n",
    "        self.x_val = x_val\n",
    "        self.best_feature = None\n",
    "        self.best_feature_value = None\n",
    "\n",
    "        self.kernel_size = kernel_size#[3,3]\n",
    "        self.kernel_n = kernel_n# 30\n",
    "        self.input_shape = input_shape # [70,64,64,3]\n",
    "\n",
    "        self.pred_val = None # 갖는 이미지의 평균값, 피팅이 완료되면 y_val, x_val은 버리도록(메모리낭비)\n",
    "\n",
    "        self.l_tree = None\n",
    "        self.r_tree = None\n",
    "\n",
    "        self.sample_ratio_by_tree = sample_ratio_by_tree\n",
    "        self.weight = weight\n",
    "\n",
    "        if kernel_cords is None:\n",
    "            ax1 = np.random.randint(input_shape[1] - kernel_size[0], size=kernel_n).reshape(-1,1)\n",
    "            ax2 = np.random.randint(input_shape[2] - kernel_size[1], size=kernel_n).reshape(-1,1)\n",
    "            ax3 = np.random.randint(input_shape[3], size=kernel_n).reshape(-1,1)\n",
    "\n",
    "            self.kernel_cords = np.concatenate([ax1,ax2,ax3],axis = 1)\n",
    "        else:\n",
    "            self.kernel_cords = kernel_cords\n",
    "\n",
    "\n",
    "\n",
    "    # def obj_fun_bhattacharyya_dist(self, l_values, r_values):\n",
    "        \n",
    "\n",
    "    #     l_arr = np.float32(l_values)\n",
    "    #     r_arr = np.float32(r_values)\n",
    "\n",
    "    #     max_val = np.max(np.concatenate([l_arr,r_arr]))\n",
    "\n",
    "    #     hist_cv_l = cv2.calcHist([l_arr],[0],None,[40],[0,max_val])\n",
    "    #     hist_cv_r = cv2.calcHist([r_arr],[0],None,[40] ,[0,max_val])    #[100] 빈수, [0,256]값 범위 \n",
    "\n",
    "    #     dist = cv2.compareHist(hist_cv_l, hist_cv_r, cv2.HISTCMP_BHATTACHARYYA) #작을수록 유사도큼\n",
    "\n",
    "    #     return dist * -1\n",
    "\n",
    "    def obj_fun(self, l_values, r_values):\n",
    "        # 고농도지점의 오차에 가중치를 더 주는 방식으로 수정할 필요가 있음\n",
    "\n",
    "        # np.mean(y, axis = 0)\n",
    "        l_mean = np.mean(l_values, axis = 0) # 0차원이 샘플수 일때\n",
    "        r_mean = np.mean(r_values, axis = 0)\n",
    "\n",
    "        l_len = len(l_values)\n",
    "        r_len = len(r_values)\n",
    "        # np.mean(((l_values - np.mean(l_values, axis = 0))**2)**0.5, axis = 0)\n",
    "        l_sqd_error = ((l_values - np.mean(l_values, axis = 0))**2)**0.5\n",
    "        \n",
    "        r_sqd_error = ((r_values - np.mean(r_values, axis = 0))**2)**0.5\n",
    "        \n",
    "\n",
    "        l_weights_minmax = (l_values - np.min(l_values))/(np.max(l_values) - np.min(l_values))\n",
    "        r_weights_minmax = (r_values - np.min(r_values))/(np.max(r_values) - np.min(r_values))\n",
    "\n",
    "        l_mse = np.mean(np.mean(l_sqd_error*l_weights_minmax, axis = 0))\n",
    "        r_mse = np.mean(np.mean(r_sqd_error*r_weights_minmax, axis = 0))\n",
    "\n",
    "        mse_weighted =  (l_mse * l_len + r_mse * r_len)/(l_len + r_len)\n",
    "\n",
    "        return mse_weighted\n",
    "\n",
    "\n",
    "    def fit(self, ):\n",
    "        best_score = None\n",
    "        for cords in self.kernel_cords:  #컬럼_피처 루프\n",
    "            \n",
    "            #서브샘플로 뽑은 데이터에서만 기준을 찾고 평가는 전체 y_val에서 함으로써 과적합 가능성이 있는 피처는 거르는 효과를 기대할 수 있음\n",
    "            sub_sample_ind = np.random.choice(range(len(self.x_val)),int(len(self.x_val) * self.sample_ratio_by_tree))\n",
    "            val_sample_ind = np.array(list(set(list(range(len(self.x_val)))) - set(sub_sample_ind)))\n",
    "\n",
    "            feat_data = self.x_val[sub_sample_ind,cords[0]:cords[0]+self.kernel_size[0],cords[1]:cords[1]+self.kernel_size[1],cords[2]]\n",
    "            val_xdata = self.x_val[val_sample_ind,cords[0]:cords[0]+self.kernel_size[0],cords[1]:cords[1]+self.kernel_size[1],cords[2]]\n",
    "            val_ydata = self.y_val[val_sample_ind]\n",
    "            # feat_data = self.x_val[:,cords[0]:cords[0]+self.kernel_size[0],cords[1]:cords[1]+self.kernel_size[1],cords[2]]\n",
    "\n",
    "\n",
    "            if len(set(feat_data.mean(axis = (1,2)))) == 1:\n",
    "\n",
    "                ## 모든 kernel_cords에서 특징이 똑같은루프만 나오면 루프를 다 돌아도 best_score = None 상태로 남음\n",
    "                ## 이상태에서 아래 피팅 부분으로 돌아가면 에러남\n",
    "                continue\n",
    "            elif len(set(feat_data.mean(axis = (1,2)))) >= 100:\n",
    "                selected_feat_vals = list(np.random.choice(list(set(feat_data.mean(axis = (1,2)))),100, replace = False))\n",
    "            else:\n",
    "                selected_feat_vals = list(set(feat_data.mean(axis = (1,2))))\n",
    "\n",
    "        \n",
    "            # 샘플내에서 oob 검증으로 과적합 방지하기...추가\n",
    "            for j in selected_feat_vals: #한 컬럼내에서 분류기준나누기 위한 루프\n",
    "\n",
    "                left_ind = val_xdata.mean(axis = (1,2)) < j\n",
    "\n",
    "                # x_val에서 서브샘플의 값을 기준으로 정한것이지만 전체 y_val에 대해 평가함으로써 과적합 방지효과 기대\n",
    "                y_left = val_ydata[left_ind]\n",
    "                y_right = val_ydata[~left_ind]\n",
    "\n",
    "                if len(y_left) * len(y_right) != 0:\n",
    "\n",
    "                    if self.best_feature is None:\n",
    "                        self.best_feature = cords\n",
    "                        self.best_feature_value = j\n",
    "                        best_score = self.obj_fun(y_left, y_right)\n",
    "                        \n",
    "                    else:\n",
    "                        new_score = self.obj_fun(y_left, y_right)\n",
    "                        if new_score < best_score:\n",
    "                            self.best_feature = cords\n",
    "                            self.best_feature_value = j\n",
    "                            best_score = new_score\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "        if best_score is None:\n",
    "            self.is_terminal = True\n",
    "            return None\n",
    "        \n",
    "                        \n",
    "\n",
    "\n",
    "        if self.max_depth >= self.i_depth:\n",
    "            # 찾은 최적값으로 좌우 할당\n",
    "            x_val_meaned_bykernel = self.x_val[:,self.best_feature[0]:self.best_feature[0]+self.kernel_size[0],self.best_feature[1]:self.best_feature[1]+self.kernel_size[1],self.best_feature[2]].mean(axis = (1,2))\n",
    "    \n",
    "            left_ind = x_val_meaned_bykernel < self.best_feature_value\n",
    "            \n",
    "            y_left = self.y_val[left_ind]\n",
    "            y_right = self.y_val[~left_ind]\n",
    "\n",
    "            x_left = self.x_val[left_ind]\n",
    "            x_right = self.x_val[~left_ind]\n",
    "\n",
    "            remove_ind = collections.Counter(np.where(self.kernel_cords == self.best_feature)[0]).most_common()[0][0]\n",
    "            sliced_kernels = np.delete(self.kernel_cords,remove_ind,axis = 0)\n",
    "\n",
    "            if len(y_left) > self.minimum_sample_leaf:\n",
    "                \n",
    "                self.l_tree = tree(kernel_cords=sliced_kernels,max_depth = self.max_depth,i_depth = self.i_depth + 1, minimum_sample_leaf = self.minimum_sample_leaf, x_val = x_left, y_val = y_left, is_terminal=False, kernel_size=self.kernel_size, kernel_n=self.kernel_n, input_shape=self.input_shape,sample_ratio_by_tree = self.sample_ratio_by_tree,weight=self.weight)\n",
    "                self.l_tree.fit()\n",
    "               \n",
    "            else:\n",
    "                #마지막 리프라서 피팅할필요 없이 y_val 평균으로 예측만 하면 됨\n",
    "                #여기서 y_val이 없는 경우가 있음 이때 nan 리턴되서 에러, 먼저 해결\n",
    "                if len(y_left) != 0 :\n",
    "                    self.l_tree = tree(kernel_cords=sliced_kernels,max_depth = self.max_depth,i_depth = self.i_depth + 1, minimum_sample_leaf = self.minimum_sample_leaf, x_val = x_left, y_val = y_left, is_terminal=True, kernel_size=self.kernel_size, kernel_n=self.kernel_n, input_shape=self.input_shape,sample_ratio_by_tree = self.sample_ratio_by_tree,weight=self.weight)\n",
    "                else:\n",
    "                    self.is_terminal = True\n",
    "            if len(y_right) > self.minimum_sample_leaf:\n",
    "                self.r_tree = tree(kernel_cords=sliced_kernels,max_depth = self.max_depth,i_depth = self.i_depth + 1, minimum_sample_leaf = self.minimum_sample_leaf, x_val = x_right, y_val = y_right, is_terminal=False, kernel_size=self.kernel_size, kernel_n=self.kernel_n, input_shape=self.input_shape,sample_ratio_by_tree = self.sample_ratio_by_tree,weight=self.weight)\n",
    "                self.r_tree.fit()\n",
    "            else:\n",
    "                #마지막 리프라서 피팅할필요 없이 y_val 평균으로 예측만 하면 됨\n",
    "                #여기서 y_val이 없는 경우가 있음 이때 nan 리턴되서 에러, 먼저 해결\n",
    "                if len(y_right) !=0:\n",
    "                    self.r_tree = tree(kernel_cords=sliced_kernels,max_depth = self.max_depth,i_depth = self.i_depth + 1, minimum_sample_leaf = self.minimum_sample_leaf, x_val = x_right, y_val = y_right, is_terminal=True, kernel_size=self.kernel_size, kernel_n=self.kernel_n, input_shape=self.input_shape,sample_ratio_by_tree = self.sample_ratio_by_tree,weight=self.weight)\n",
    "                else:\n",
    "                    self.is_terminal = True\n",
    "        else:\n",
    "            self.is_terminal = True\n",
    "\n",
    "\n",
    "    def i_pred(self,x_data):\n",
    "        if self.is_terminal:\n",
    "            pred = self.y_val.mean(axis = 0)\n",
    "            return pred\n",
    "        \n",
    "        i_x_val_meaned_bykernel = x_data[self.best_feature[0]:self.best_feature[0]+self.kernel_size[0],self.best_feature[1]:self.best_feature[1]+self.kernel_size[1],self.best_feature[2]].mean(axis = (0,1))\n",
    "    \n",
    "\n",
    "        if i_x_val_meaned_bykernel < self.best_feature_value:\n",
    "            if self.l_tree.is_terminal:\n",
    "                pred = self.l_tree.y_val.mean(axis = 0)   # 트리가 자료를 지니고있을 필요는 없음 (평균값만 저장하면 됨)\n",
    "            else:\n",
    "                pred = self.l_tree.i_pred(x_data)\n",
    "        else:\n",
    "            if self.r_tree.is_terminal:\n",
    "                pred = self.r_tree.y_val.mean(axis = 0)\n",
    "            else:\n",
    "                pred = self.r_tree.i_pred(x_data)\n",
    "\n",
    "        return pred.reshape(-1,self.input_shape[1],self.input_shape[2],1)\n",
    "\n",
    "    def prediction(self, x_arr):\n",
    "\n",
    "        if len(x_arr.shape) != 4:\n",
    "            raise Exception('shape error')\n",
    "        else:\n",
    "        \n",
    "            results = []\n",
    "            for i in range(len(x_arr)):\n",
    "                i_val = x_arr[i,:]\n",
    "                \n",
    "                result = self.i_pred(i_val)\n",
    "                results.append(result)\n",
    "\n",
    "            return results\n",
    "    \n",
    "    def get_tree_structure(self):\n",
    "        def get_info_dic(i_tree):\n",
    "            result = {\n",
    "            'best_feature': i_tree.best_feature,\n",
    "            'best_feature_value': i_tree.best_feature_value,\n",
    "            'terminal': i_tree.is_terminal,\n",
    "            'depth': i_tree.i_depth,\n",
    "            }\n",
    "            \n",
    "            if i_tree.l_tree is not None:\n",
    "                result['l_tree'] = get_info_dic(i_tree.l_tree)\n",
    "            \n",
    "            if i_tree.r_tree is not None:\n",
    "                result['r_tree'] = get_info_dic(i_tree.r_tree)\n",
    "\n",
    "            return result\n",
    "        \n",
    "        info = get_info_dic(self)\n",
    "        return info"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ga-bag-ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorgpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4dfcec166549515651fe6305b8170d114ac82791493775815ad403a25f333b28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
