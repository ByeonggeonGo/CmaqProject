{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tarfile\n",
    "\n",
    "\n",
    "import zipfile\n",
    "from glob import glob\n",
    "import os\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import geopandas as gpd # GeoPandas(지오판다스)\n",
    "from shapely.geometry import Polygon, LineString, Point\n",
    "path = os.getcwd()\n",
    "\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "from rasterio.transform import from_origin\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "from geocube.api.core import make_geocube\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emission 117번 시나리오 없음\n",
    "emiss_s_list = glob(os.path.join(\"d:\",\"Emission\",\"*Jul.tar.gz\",))\n",
    "emiss_s_num = [os.path.split(path)[-1].split(\"_\")[1] for path in emiss_s_list]\n",
    "emiss_info_df = pd.DataFrame()\n",
    "emiss_info_df.loc[:,'path'] = emiss_s_list\n",
    "emiss_info_df.loc[:,'s_num'] = emiss_s_num\n",
    "\n",
    "concentration_s_list = glob(os.path.join(\"d:\",\"Concentration\",\"*.tar.gz\",))\n",
    "concentration_s_num = [os.path.split(path)[-1].split(\"_\")[1] for path in concentration_s_list]\n",
    "concentration_info_df = pd.DataFrame()\n",
    "concentration_info_df.loc[:,'path'] = concentration_s_list\n",
    "concentration_info_df.loc[:,'s_num'] = concentration_s_num\n",
    "\n",
    "all_conc_emis_pathinfo = pd.merge(emiss_info_df,concentration_info_df,how='left',on='s_num', suffixes=['_emission','_concentration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_emission</th>\n",
       "      <th>s_num</th>\n",
       "      <th>path_concentration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d:Emission\\RSM_105_Apr_Jul.tar.gz</td>\n",
       "      <td>105</td>\n",
       "      <td>d:Concentration\\RSM_105_ACONC.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d:Emission\\RSM_106_Apr_Jul.tar.gz</td>\n",
       "      <td>106</td>\n",
       "      <td>d:Concentration\\RSM_106_ACONC.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d:Emission\\RSM_107_Apr_Jul.tar.gz</td>\n",
       "      <td>107</td>\n",
       "      <td>d:Concentration\\RSM_107_ACONC.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d:Emission\\RSM_108_Apr_Jul.tar.gz</td>\n",
       "      <td>108</td>\n",
       "      <td>d:Concentration\\RSM_108_ACONC.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d:Emission\\RSM_109_Apr_Jul.tar.gz</td>\n",
       "      <td>109</td>\n",
       "      <td>d:Concentration\\RSM_109_ACONC.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>d:Emission\\RSM_100_Apr_Jul.tar.gz</td>\n",
       "      <td>100</td>\n",
       "      <td>d:Concentration\\RSM_100_ACONC.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>d:Emission\\RSM_101_Apr_Jul.tar.gz</td>\n",
       "      <td>101</td>\n",
       "      <td>d:Concentration\\RSM_101_ACONC.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>d:Emission\\RSM_102_Apr_Jul.tar.gz</td>\n",
       "      <td>102</td>\n",
       "      <td>d:Concentration\\RSM_102_ACONC.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>d:Emission\\RSM_103_Apr_Jul.tar.gz</td>\n",
       "      <td>103</td>\n",
       "      <td>d:Concentration\\RSM_103_ACONC.tar.gz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>d:Emission\\RSM_104_Apr_Jul.tar.gz</td>\n",
       "      <td>104</td>\n",
       "      <td>d:Concentration\\RSM_104_ACONC.tar.gz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         path_emission s_num  \\\n",
       "0    d:Emission\\RSM_105_Apr_Jul.tar.gz   105   \n",
       "1    d:Emission\\RSM_106_Apr_Jul.tar.gz   106   \n",
       "2    d:Emission\\RSM_107_Apr_Jul.tar.gz   107   \n",
       "3    d:Emission\\RSM_108_Apr_Jul.tar.gz   108   \n",
       "4    d:Emission\\RSM_109_Apr_Jul.tar.gz   109   \n",
       "..                                 ...   ...   \n",
       "113  d:Emission\\RSM_100_Apr_Jul.tar.gz   100   \n",
       "114  d:Emission\\RSM_101_Apr_Jul.tar.gz   101   \n",
       "115  d:Emission\\RSM_102_Apr_Jul.tar.gz   102   \n",
       "116  d:Emission\\RSM_103_Apr_Jul.tar.gz   103   \n",
       "117  d:Emission\\RSM_104_Apr_Jul.tar.gz   104   \n",
       "\n",
       "                       path_concentration  \n",
       "0    d:Concentration\\RSM_105_ACONC.tar.gz  \n",
       "1    d:Concentration\\RSM_106_ACONC.tar.gz  \n",
       "2    d:Concentration\\RSM_107_ACONC.tar.gz  \n",
       "3    d:Concentration\\RSM_108_ACONC.tar.gz  \n",
       "4    d:Concentration\\RSM_109_ACONC.tar.gz  \n",
       "..                                    ...  \n",
       "113  d:Concentration\\RSM_100_ACONC.tar.gz  \n",
       "114  d:Concentration\\RSM_101_ACONC.tar.gz  \n",
       "115  d:Concentration\\RSM_102_ACONC.tar.gz  \n",
       "116  d:Concentration\\RSM_103_ACONC.tar.gz  \n",
       "117  d:Concentration\\RSM_104_ACONC.tar.gz  \n",
       "\n",
       "[118 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_conc_emis_pathinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/workspace'\n",
    "data_path = os.path.join(path,'cmaqProjectdata')\n",
    "proj_path = os.path.join(path,'repos','cmaqProject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기상측정망, 대기질측정망 메타정보 정리\n",
    "em_meta = pd.read_csv(glob(os.path.join(path,\"시간단위_기상자료개방포털\",\"rawdata\",\"meta\",\"*.csv\",))[0],encoding='cp949')\n",
    "geo_point = []\n",
    "for i in range(len(em_meta)):\n",
    "    x,y = em_meta.loc[i,'경도'], em_meta.loc[i,'위도']\n",
    "    geo_point.append(Point(x,y))\n",
    "    \n",
    "\n",
    "em_meta['geometry'] = geo_point\n",
    "\n",
    "em_point_gdf = gpd.GeoDataFrame(em_meta, geometry= 'geometry')\n",
    "em_point_gdf.crs = {'init':'epsg:4326'}\n",
    "\n",
    "url = 'http://apis.data.go.kr/B552584/MsrstnInfoInqireSvc/getMsrstnList'\n",
    "key = \"k5wXUhoJHwee1cncQCBmm81YbQ+exttb0vdJcyF5GuGJn0mbGBNNL/ER2VfkrJMlExfc+FZjPeRuOM2bvgDYyQ==\"\n",
    "\n",
    "# params ={'serviceKey' : key, 'addr': '서울', 'stationName': '종로구', 'pageNo': 1, 'numOfRows': 10,'returnType': 'json'}\n",
    "params ={'serviceKey' : key, 'pageNo': 1, 'numOfRows': 640,'returnType': 'json'}\n",
    "response = requests.get(url, params=params, verify=False)\n",
    "\n",
    "data_dic = response.json()\n",
    "site_info = pd.DataFrame(data_dic['response']['body']['items'])\n",
    "\n",
    "point_list = []\n",
    "for i in range(len(site_info)):\n",
    "    try:\n",
    "        point_list.append(Point(float(site_info.dmY[i]), float(site_info.dmX[i])))\n",
    "    except:\n",
    "        point_list.append(None)\n",
    "\n",
    "site_info.loc[:,'geometry'] = point_list\n",
    "site_info_dropna = site_info.loc[~site_info.isna().dmX.values]\n",
    "\n",
    "site_info_dropna = gpd.GeoDataFrame(site_info_dropna, geometry = 'geometry')\n",
    "site_info_dropna.crs = em_point_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대기질자료 불러오기\n",
    "airpolutant_monitoring_2013_list = glob(os.path.join(path,\"시간단위대기질자료\",\"rawdata\",\"extract\",\"2013*\",))\n",
    "airpolutant_monitoring_2013_list\n",
    "data_list = []\n",
    "for i in airpolutant_monitoring_2013_list:\n",
    "    temp_data = pd.read_excel(i)\n",
    "    data_list.append(temp_data)\n",
    "air_pol_2013 = pd.concat(data_list)\n",
    "air_pol_2013.info()\n",
    "\n",
    "#기상자료 불러오기\n",
    "em_dataset_path_list = glob(os.path.join(path,\"시간단위_기상자료개방포털\",\"rawdata\",\"extract\",\"*.csv\",))\n",
    "em_dataset_list = [pd.read_csv(path, encoding='cp949') for path in em_dataset_path_list]\n",
    "em_df = pd.concat(em_dataset_list, axis = 0)\n",
    "em_df.info()\n",
    "datetime_airpol = [datetime.datetime(int(date[:4]),int(date[4:6]),int(date[6:8]),int(date[8:] if date[8:] !='24' else '0')) for date in air_pol_2013.측정일시.values.astype(str)]\n",
    "air_pol_2013.loc[:,'datetime'] = datetime_airpol\n",
    "em_df.loc[:,'datetime'] = pd.to_datetime(em_df.일시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Go\\anaconda3\\envs\\tensorgpu\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py:122: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    }
   ],
   "source": [
    "# lcc프로젝션 기본 레스터 제작\n",
    "projout = '+proj=lcc +lat_1=30 +lat_2=60 +lon_1=126 +lat_0=38 +lon_0=126 +ellps=GRS80 +units=m'\n",
    "\n",
    "# out_grid = make_geocube(vector_data=test_data, measurements=[\"습도(%)\"], geom=geom,resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "x_m = list(range(-180000,-180000 + 9000 * 68, 9000))\n",
    "y_m = list(range(-585000,-585000 + 9000 * 83, 9000))\n",
    "\n",
    "print(len(x_m), len(y_m))\n",
    "\n",
    "grid_points = []\n",
    "for x_i in x_m:\n",
    "    for y_i in y_m:\n",
    "        grid_points.append(Point(x_i,y_i))\n",
    "\n",
    "grid_data = pd.DataFrame(grid_points, columns=['geometry'])\n",
    "\n",
    "grid_data = gpd.GeoDataFrame(grid_data, geometry='geometry')\n",
    "grid_data.crs = em_point_gdf.to_crs(projout).crs\n",
    "grid_data.loc[:,'x_m'] = grid_data.geometry.x\n",
    "grid_data.loc[:,'y_m'] = grid_data.geometry.y\n",
    "grid_data.loc[:,'value'] = 0\n",
    "\n",
    "out_grid = make_geocube(vector_data=grid_data, measurements=[\"value\"],resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "out_grid[\"value\"].rio.to_raster(\"base_lcc.tif\")\n",
    "# 레스터 좌표변환\n",
    "# 5181로 변환하면 좌표들 약간 틀어짐\n",
    "# lcc로 처리 해야함\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "# dst_crs = 'epsg: 5181'\n",
    "dst_crs = '+proj=lcc +lat_1=30 +lat_2=60 +lon_1=126 +lat_0=38 +lon_0=126 +ellps=GRS80 +units=m'\n",
    "\n",
    "with rasterio.open(os.path.join(path,\"base_lcc.tif\")) as src:\n",
    "\n",
    "    transform, width, height = calculate_default_transform(\n",
    "                    src.crs, \n",
    "                    dst_crs, \n",
    "                    src.width, \n",
    "                    src.height, \n",
    "                    *src.bounds)\n",
    "   \n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "\n",
    "    with rasterio.open(os.path.join(path,\"base_lcc_lcc.tif\"), 'w', **kwargs) as dst:\n",
    "            \n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    resampling=Resampling.nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pm10 합산해서 계산하는 수식 및 chem 리스트\n",
    "pm_10_cal = \"(1.0*ASO4J[1])+(1.0*ASO4I[1])+(1.0*ANH4J[1])+(1.0*ANH4I[1])+(1.0*ANO3J[1])+(1.0*ANO3I[1])+(1.0*AALKJ[1])+(1.0*AXYL1J[1])+(1.0*AXYL2J[1])+(1.0*AXYL3J[1])+(1.0*ATOL1J[1])+(1.0*ATOL2J[1])+(1.0*ATOL3J[1])+(1.0*ABNZ1J[1])+(1.0*ABNZ2J[1])+(1.0*ABNZ3J[1])+(1.0*ATRP1J[1])+(1.0*ATRP2J[1])+(1.0*AISO1J[1])+(1.0*AISO2J[1])+(1.0*AISO3J[1])+(1.0*ASQTJ[1])+(1.0*AORGCJ[1])+(1.0*AORGPAJ[1])+(1.0*AORGPAI[1])+(1.0*AECJ[1])+(1.0*AECI[1])+(1.0*A25J[1])+(1.0*ANAJ[1])+(1.0*ACLJ[1])+(1.0*ACLI[1])+(1.0*AOLGAJ[1])+(1.0*AOLGBJ[1])+(1.0*ACORS[1])+(1.0*ASOIL[1])+(1.0*ANAK[1])+(1.0*ACLK[1])+(1.0*ASO4K[1])+(1.0*ANH4K[1])+(1.0*ANO3K[1])\"\n",
    "pm_10_chem_list = [chem[5:-4] for chem in pm_10_cal.split(\"+\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "projout = '+proj=lcc +lat_1=30 +lat_2=60 +lon_1=126 +lat_0=38 +lon_0=126 +ellps=GRS80 +units=m'\n",
    "col_list = ['기온(°C)', '강수량(mm)', '풍속(m/s)', '풍향(16방위)', '습도(%)', '증기압(hPa)', '이슬점온도(°C)', '현지기압(hPa)', '해면기압(hPa)', '일조(hr)', '일사(MJ/m2)', '적설(cm)', '3시간신적설(cm)', '전운량(10분위)', '중하층운량(10분위)',]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:Emission\\RSM_106_Apr_Jul.tar.gz d:Concentration\\RSM_106_ACONC.tar.gz\n",
      "e:dataset_record\\dataset_106.tfr\n",
      "2013-03-22\n",
      "CMAQ_PM10 데이터셋:  (24, 82, 67, 1) SMOKE_모든변수 데이터셋:  (24, 82, 67, 45)\n",
      "2013-03-22 00:00:00\n",
      "2013-03-22 01:00:00\n",
      "2013-03-22 02:00:00\n",
      "2013-03-22 03:00:00\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_conc_emis_pathinfo))[1:2]:\n",
    "    path_emis = all_conc_emis_pathinfo.path_emission.values[i]\n",
    "    path_conc = all_conc_emis_pathinfo.path_concentration.values[i]\n",
    "    s_num = all_conc_emis_pathinfo.s_num[i]\n",
    "    \n",
    "    print(path_emis, path_conc)\n",
    "    tar = tarfile.open(path_conc,\"r:gz\")\n",
    "    tar.extractall(os.path.join(\"e:\",\"dataset_record\",\"Concentration\",))\n",
    "    tar.close()\n",
    "\n",
    "    tar = tarfile.open(path_emis,\"r:gz\")\n",
    "    tar.extractall(os.path.join(\"e:\",\"dataset_record\",\"Emission\",))\n",
    "    tar.close()\n",
    "\n",
    "\n",
    "    # 날짜별 smoke, cmaq데이터셋 경로 정리\n",
    "    emis_list = glob(os.path.join(\"e:\",\"dataset_record\",\"Emission\",f\"RSM_{s_num}\",\"*\"))         \n",
    "    concentration_list = glob(os.path.join(\"e:\",\"dataset_record\",\"Concentration\",f\"RSM_{s_num}\",\"*\"))           \n",
    "\n",
    "    emis_day_list = [os.path.split(path)[-1].split('.')[-5] for path in emis_list]\n",
    "    concentration_day_list = [os.path.split(path)[-1].split('.')[-2] for path in concentration_list]\n",
    "\n",
    "    \n",
    "    concentration_day_list_datetime = []\n",
    "    for date in concentration_day_list:\n",
    "\n",
    "        start_date = datetime.date(int(date[:4]), 1, 1) + datetime.timedelta(-1)\n",
    "        d_day = int(date[4:])\n",
    "        target_date = start_date + datetime.timedelta(d_day)\n",
    "\n",
    "        concentration_day_list_datetime.append(target_date)\n",
    "\n",
    "    emis_day_list_datetime = []\n",
    "    for date in emis_day_list:\n",
    "        target_date = datetime.date(int(date[:4]), int(date[4:6]), int(date[6:]))\n",
    "        emis_day_list_datetime.append(target_date)\n",
    "\n",
    "    emis_info_df = pd.DataFrame()\n",
    "    emis_info_df.loc[:,['date']] = emis_day_list_datetime\n",
    "    emis_info_df.loc[:,['path']] = emis_list\n",
    "\n",
    "    concentration_info_df = pd.DataFrame()\n",
    "    concentration_info_df.loc[:,['date']] = concentration_day_list_datetime\n",
    "    concentration_info_df.loc[:,['path']] = concentration_list\n",
    "    concentration_info_df = concentration_info_df.sort_values('date')\n",
    "    concentration_info_df.index = range(len(concentration_info_df))\n",
    "\n",
    "    con_emis_info_merged_df = pd.merge(concentration_info_df, emis_info_df, how='left', on='date', suffixes=['_concentration', '_emission'])\n",
    "        \n",
    "    con_emis_info_merged_df_dropna = con_emis_info_merged_df.loc[~con_emis_info_merged_df.path_emission.isna(),]\n",
    "    con_emis_info_merged_df_dropna.index = range(len(con_emis_info_merged_df_dropna))\n",
    "\n",
    "    writer_image = tf.io.TFRecordWriter(os.path.join(\"e:\",\"dataset_record\",f\"dataset_{s_num}.tfr\"))\n",
    "    print(os.path.join(\"e:\",\"dataset_record\",f\"dataset_{s_num}.tfr\"))\n",
    "\n",
    "    # for i in range(len(con_emis_info_merged_df_dropna)):\n",
    "    for i in range(len(con_emis_info_merged_df_dropna))[:1]:\n",
    "    \n",
    "        today = con_emis_info_merged_df_dropna.loc[i].date\n",
    "        print(today)\n",
    "        # 해당날짜의 데이터셋 불러오기\n",
    "        with Dataset(con_emis_info_merged_df_dropna.loc[i].path_concentration, 'r') as concen_data, Dataset(con_emis_info_merged_df_dropna.loc[i].path_emission, 'r') as emis_data:\n",
    "\n",
    "            # concen_data = Dataset(con_emis_info_merged_df_dropna.loc[i].path_concentration, 'r')\n",
    "            # emis_data = Dataset(con_emis_info_merged_df_dropna.loc[i].path_emission, 'r')\n",
    "\n",
    "            # 해당날짜의 관련변수 합으로 pm10 CMAQ array형성\n",
    "            pm10_chemlist = [np.array(concen_data.variables[chem]) for chem in pm_10_chem_list]\n",
    "            day_concen_pm10 = np.sum(pm10_chemlist, axis=0)\n",
    "            day_concen_pm10 = day_concen_pm10.reshape(day_concen_pm10.shape[0],day_concen_pm10.shape[2],day_concen_pm10.shape[3],-1)\n",
    "\n",
    "            # 해당날짜의 smoke 모든변수 array 형성, 연직방향으로는 맨 밑레이어만 사용\n",
    "            smoke_chem_list = list(set(emis_data.variables.keys()) - set(['TFLAG']))\n",
    "            smoke_chem_arr_list = [np.array(emis_data.variables[chem])[:,0:1,:,:].reshape(25,82,67,-1) for chem in smoke_chem_list]\n",
    "            day_smoke_allval = np.concatenate(smoke_chem_arr_list, axis=3)\n",
    "            day_smoke_allval = day_smoke_allval[:24]\n",
    "\n",
    "            print('CMAQ_PM10 데이터셋: ',day_concen_pm10.shape, 'SMOKE_모든변수 데이터셋: ',day_smoke_allval.shape)\n",
    "\n",
    "            # for hour_ind in range(24):\n",
    "            for hour_ind in range(4):\n",
    "                datetime_ind = datetime.datetime(today.year, today.month, today.day, hour_ind)\n",
    "                print(str(datetime_ind))\n",
    "\n",
    "                air_pol_datetime_ind_df = air_pol_2013.loc[air_pol_2013.datetime == datetime_ind]\n",
    "                air_pol_datetime_ind_df.index = range(len(air_pol_datetime_ind_df))\n",
    "\n",
    "                air_pol_datetime_ind_df_geoinfo = pd.merge(air_pol_datetime_ind_df,site_info_dropna.loc[:,['stationName', 'geometry']],how='left',left_on='측정소명',right_on='stationName')\n",
    "                air_pol_datetime_ind_df_geoinfo = air_pol_datetime_ind_df_geoinfo.loc[~air_pol_datetime_ind_df_geoinfo.stationName.isna()]\n",
    "                air_pol_datetime_ind_df_geoinfo.index = range(len(air_pol_datetime_ind_df_geoinfo))\n",
    "                air_pol_datetime_ind_df_geoinfo = gpd.GeoDataFrame(air_pol_datetime_ind_df_geoinfo, geometry='geometry')\n",
    "                air_pol_datetime_ind_df_geoinfo = air_pol_datetime_ind_df_geoinfo.fillna(0)\n",
    "                air_pol_datetime_ind_df_geoinfo = air_pol_datetime_ind_df_geoinfo.loc[~(air_pol_datetime_ind_df_geoinfo.PM10 == -999)]  # 값이 -999찍혀있을때가 있음 기기오작동으로보고 제거\n",
    "                air_pol_datetime_ind_df_geoinfo.index = range(len(air_pol_datetime_ind_df_geoinfo))\n",
    "\n",
    "                # out_grid = make_geocube(vector_data=test_data, measurements=[\"습도(%)\"], geom=geom,resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "                out_grid = make_geocube(vector_data=air_pol_datetime_ind_df_geoinfo, measurements=[\"PM10\"],resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "                out_grid[\"PM10\"].rio.to_raster(\"rasterized_air_pol.tif\")\n",
    "\n",
    "\n",
    "                dst_crs = projout\n",
    "                with rasterio.open(os.path.join(path,\"rasterized_air_pol.tif\")) as src:\n",
    "                    # print(src.width, src.height, *src.bounds,)\n",
    "                    transform, width, height = calculate_default_transform(\n",
    "                                    src.crs, \n",
    "                                    dst_crs, \n",
    "                                    src.width, \n",
    "                                    src.height, \n",
    "                                    *src.bounds)\n",
    "                \n",
    "                    kwargs = src.meta.copy()\n",
    "                    kwargs.update({\n",
    "                        'crs': dst_crs,\n",
    "                        'transform': transform,\n",
    "                        'width': width,\n",
    "                        'height': height\n",
    "                    })\n",
    "\n",
    "                    with rasterio.open(os.path.join(path,\"rasterized_air_pol_lcc.tif\"), 'w', **kwargs) as dst:\n",
    "                            \n",
    "                            for i in range(1, src.count + 1):\n",
    "                                reproject(\n",
    "                                    source=rasterio.band(src, i),\n",
    "                                    destination=rasterio.band(dst, i),\n",
    "                                    src_transform=src.transform,\n",
    "                                    src_crs=src.crs,\n",
    "                                    dst_transform=transform,\n",
    "                                    dst_crs=dst_crs,\n",
    "                                    resampling=Resampling.nearest)\n",
    "\n",
    "            \n",
    "\n",
    "                with rasterio.open(os.path.join(path,\"base_lcc_lcc.tif\")) as src, rasterio.open(os.path.join(path,\"rasterized_air_pol_lcc.tif\")) as src2:\n",
    "                    raster_list = [src, src2]\n",
    "                    # print(src.read(1).shape, src2.read(1).shape,)\n",
    "                    mosaic, output = merge(raster_list)\n",
    "\n",
    "                    output_meta = src2.meta.copy()\n",
    "                    output_meta.update(\n",
    "                        {\"driver\": \"GTiff\",\n",
    "                            \"height\": mosaic.shape[1],\n",
    "                            \"width\": mosaic.shape[2],\n",
    "                            \"transform\": output,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    with rasterio.open(os.path.join(path,\"rasterized_air_pol_lcc_final.tif\"), \"w\", **output_meta) as m:\n",
    "                        m.write(mosaic)\n",
    "\n",
    "                with rasterio.open(os.path.join(path,\"rasterized_air_pol_lcc_final.tif\")) as src:\n",
    "                    air_pol_pm10_arr = src.read(1)\n",
    "                    air_pol_pm10_arr = air_pol_pm10_arr.reshape(1,82,67,1)\n",
    "                    # print(air_pol_pm10_arr.shape)\n",
    "                em_df_ind_df = em_df.loc[em_df.datetime == datetime_ind]\n",
    "                em_df_ind_df.index = range(len(em_df_ind_df))\n",
    "                em_df_ind_df_geoinfo = pd.merge(em_df_ind_df,em_point_gdf.loc[:,['지점', 'geometry']],how='left',on = '지점')\n",
    "\n",
    "                em_df_ind_df_geoinfo = em_df_ind_df_geoinfo.loc[~em_df_ind_df_geoinfo.geometry.isna()]\n",
    "                em_df_ind_df_geoinfo.index = range(len(em_df_ind_df_geoinfo))\n",
    "                em_df_ind_df_geoinfo = gpd.GeoDataFrame(em_df_ind_df_geoinfo, geometry='geometry')\n",
    "                em_df_ind_df_geoinfo = em_df_ind_df_geoinfo.fillna(0)\n",
    "\n",
    "\n",
    "                # out_grid = make_geocube(vector_data=test_data, measurements=[\"습도(%)\"], geom=geom,resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "\n",
    "                em_arr_list = []\n",
    "                for col_name in col_list:\n",
    "                    \n",
    "                    out_grid = make_geocube(vector_data=em_df_ind_df_geoinfo, measurements=[col_name],resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "                    out_grid[col_name].rio.to_raster(\"rasterized_em.tif\")\n",
    "\n",
    "                    dst_crs = projout\n",
    "                    with rasterio.open(os.path.join(path,\"rasterized_em.tif\")) as src:\n",
    "                        # print(src.count)\n",
    "                        transform, width, height = calculate_default_transform(\n",
    "                                        src.crs, \n",
    "                                        dst_crs, \n",
    "                                        src.width, \n",
    "                                        src.height, \n",
    "                                        *src.bounds)\n",
    "                    \n",
    "                        kwargs = src.meta.copy()\n",
    "                        kwargs.update({\n",
    "                            'crs': dst_crs,\n",
    "                            'transform': transform,\n",
    "                            'width': width,\n",
    "                            'height': height\n",
    "                        })\n",
    "\n",
    "                        with rasterio.open(os.path.join(path,\"rasterized_em_lcc.tif\"), 'w', **kwargs) as dst:\n",
    "                                \n",
    "                                for i in range(1, src.count + 1):\n",
    "                                    reproject(\n",
    "                                        source=rasterio.band(src, i),\n",
    "                                        destination=rasterio.band(dst, i),\n",
    "                                        src_transform=src.transform,\n",
    "                                        src_crs=src.crs,\n",
    "                                        dst_transform=transform,\n",
    "                                        dst_crs=dst_crs,\n",
    "                                        resampling=Resampling.nearest)\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "                    with rasterio.open(os.path.join(path,\"base_lcc_lcc.tif\")) as src, rasterio.open(os.path.join(path,\"rasterized_em_lcc.tif\")) as src2:\n",
    "                        raster_list = [src, src2]\n",
    "                        # print(src.read(1).shape, src2.read(1).shape,)\n",
    "                        mosaic, output = merge(raster_list)\n",
    "\n",
    "                        output_meta = src2.meta.copy()\n",
    "                        output_meta.update(\n",
    "                            {\"driver\": \"GTiff\",\n",
    "                                \"height\": mosaic.shape[1],\n",
    "                                \"width\": mosaic.shape[2],\n",
    "                                \"transform\": output,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                        with rasterio.open(os.path.join(path,\"rasterized_em_lcc_final.tif\"), \"w\", **output_meta) as m:\n",
    "                            m.write(mosaic)\n",
    "\n",
    "                    with rasterio.open(os.path.join(path,\"rasterized_em_lcc_final.tif\")) as src:\n",
    "                    \n",
    "                        em_arr = src.read(1)\n",
    "                        em_arr = em_arr.reshape(1,82,67,1)\n",
    "                        em_arr_list.append(em_arr)\n",
    "\n",
    "                em_arr_map = np.concatenate(em_arr_list,axis=3)\n",
    "\n",
    "                weather_t = em_arr_map[:1].tobytes()\n",
    "                air_q_t = air_pol_pm10_arr[:1].tobytes()\n",
    "                cmaq_t = day_concen_pm10[hour_ind:hour_ind+1].tobytes()\n",
    "                smoke_t = day_smoke_allval[hour_ind:hour_ind+1].tobytes()\n",
    "\n",
    "                example = tf.train.Example(\n",
    "                    features=tf.train.Features(\n",
    "                        feature={\n",
    "                            'CMAQ_t': _bytes_feature(cmaq_t),\n",
    "                            'SMOKE_t': _bytes_feature(smoke_t),\n",
    "                            'air_quality_monitoring_t': _bytes_feature(air_q_t),   \n",
    "                            'weather_monitoring_t': _bytes_feature(weather_t),\n",
    "                            'year': _bytes_feature(np.array(today.year - 2000).reshape(1,-1).tobytes()), \n",
    "                            'month': _bytes_feature(np.array(today.month).reshape(1,-1).tobytes()), \n",
    "                            'day': _bytes_feature(np.array(today.day).reshape(1,-1).tobytes()), \n",
    "                            'hour': _bytes_feature(np.array(hour_ind).reshape(1,-1).tobytes()), \n",
    "\n",
    "                        }\n",
    "                        )\n",
    "                    )\n",
    "                writer_image.write(example.SerializeToString())\n",
    "        \n",
    "    writer_image.close()\n",
    "\n",
    "    shutil.rmtree(os.path.join(\"e:\",\"dataset_record\",\"Concentration\",f\"RSM_{s_num}\"))\n",
    "    shutil.rmtree(os.path.join(\"e:\",\"dataset_record\",\"Emission\",f\"RSM_{s_num}\"))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_conc_emis_pathinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_conc_emis_pathinfo))[1:]:\n",
    "    path_emis = all_conc_emis_pathinfo.path_emission.values[i]\n",
    "    path_conc = all_conc_emis_pathinfo.path_concentration.values[i]\n",
    "    s_num = all_conc_emis_pathinfo.s_num[i]\n",
    "    \n",
    "    if s_num != 106:\n",
    "        print(path_emis, path_conc)\n",
    "        tar = tarfile.open(path_conc,\"r:gz\")\n",
    "        tar.extractall(os.path.join(\"e:\",\"dataset_record\",\"Concentration\",))\n",
    "        tar.close()\n",
    "\n",
    "        tar = tarfile.open(path_emis,\"r:gz\")\n",
    "        tar.extractall(os.path.join(\"e:\",\"dataset_record\",\"Emission\",))\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "    # 날짜별 smoke, cmaq데이터셋 경로 정리\n",
    "    emis_list = glob(os.path.join(\"e:\",\"dataset_record\",\"Emission\",f\"RSM_{s_num}\",\"*\"))         \n",
    "    concentration_list = glob(os.path.join(\"e:\",\"dataset_record\",\"Concentration\",f\"RSM_{s_num}\",\"*\"))           \n",
    "\n",
    "    emis_day_list = [os.path.split(path)[-1].split('.')[-5] for path in emis_list]\n",
    "    concentration_day_list = [os.path.split(path)[-1].split('.')[-2] for path in concentration_list]\n",
    "\n",
    "    \n",
    "    concentration_day_list_datetime = []\n",
    "    for date in concentration_day_list:\n",
    "\n",
    "        start_date = datetime.date(int(date[:4]), 1, 1) + datetime.timedelta(-1)\n",
    "        d_day = int(date[4:])\n",
    "        target_date = start_date + datetime.timedelta(d_day)\n",
    "\n",
    "        concentration_day_list_datetime.append(target_date)\n",
    "\n",
    "    emis_day_list_datetime = []\n",
    "    for date in emis_day_list:\n",
    "        target_date = datetime.date(int(date[:4]), int(date[4:6]), int(date[6:]))\n",
    "        emis_day_list_datetime.append(target_date)\n",
    "\n",
    "    emis_info_df = pd.DataFrame()\n",
    "    emis_info_df.loc[:,['date']] = emis_day_list_datetime\n",
    "    emis_info_df.loc[:,['path']] = emis_list\n",
    "\n",
    "    concentration_info_df = pd.DataFrame()\n",
    "    concentration_info_df.loc[:,['date']] = concentration_day_list_datetime\n",
    "    concentration_info_df.loc[:,['path']] = concentration_list\n",
    "    concentration_info_df = concentration_info_df.sort_values('date')\n",
    "    concentration_info_df.index = range(len(concentration_info_df))\n",
    "\n",
    "    con_emis_info_merged_df = pd.merge(concentration_info_df, emis_info_df, how='left', on='date', suffixes=['_concentration', '_emission'])\n",
    "        \n",
    "    con_emis_info_merged_df_dropna = con_emis_info_merged_df.loc[~con_emis_info_merged_df.path_emission.isna(),]\n",
    "    con_emis_info_merged_df_dropna.index = range(len(con_emis_info_merged_df_dropna))\n",
    "\n",
    "    writer_image = tf.io.TFRecordWriter(os.path.join(\"e:\",\"dataset_record\",f\"dataset_{s_num}.tfr\"))\n",
    "    print(os.path.join(\"e:\",\"dataset_record\",f\"dataset_{s_num}.tfr\"))\n",
    "\n",
    "    for i in range(len(con_emis_info_merged_df_dropna)):\n",
    "    # for i in range(len(con_emis_info_merged_df_dropna))[:1]:\n",
    "    \n",
    "        today = con_emis_info_merged_df_dropna.loc[i].date\n",
    "        print(today)\n",
    "        # 해당날짜의 데이터셋 불러오기\n",
    "        with Dataset(con_emis_info_merged_df_dropna.loc[i].path_concentration, 'r') as concen_data, Dataset(con_emis_info_merged_df_dropna.loc[i].path_emission, 'r') as emis_data:\n",
    "\n",
    "            # concen_data = Dataset(con_emis_info_merged_df_dropna.loc[i].path_concentration, 'r')\n",
    "            # emis_data = Dataset(con_emis_info_merged_df_dropna.loc[i].path_emission, 'r')\n",
    "\n",
    "            # 해당날짜의 관련변수 합으로 pm10 CMAQ array형성\n",
    "            pm10_chemlist = [np.array(concen_data.variables[chem]) for chem in pm_10_chem_list]\n",
    "            day_concen_pm10 = np.sum(pm10_chemlist, axis=0)\n",
    "            day_concen_pm10 = day_concen_pm10.reshape(day_concen_pm10.shape[0],day_concen_pm10.shape[2],day_concen_pm10.shape[3],-1)\n",
    "\n",
    "            # 해당날짜의 smoke 모든변수 array 형성, 연직방향으로는 맨 밑레이어만 사용\n",
    "            smoke_chem_list = list(set(emis_data.variables.keys()) - set(['TFLAG']))\n",
    "            smoke_chem_arr_list = [np.array(emis_data.variables[chem])[:,0:1,:,:].reshape(25,82,67,-1) for chem in smoke_chem_list]\n",
    "            day_smoke_allval = np.concatenate(smoke_chem_arr_list, axis=3)\n",
    "            day_smoke_allval = day_smoke_allval[:24]\n",
    "\n",
    "            print('CMAQ_PM10 데이터셋: ',day_concen_pm10.shape, 'SMOKE_모든변수 데이터셋: ',day_smoke_allval.shape)\n",
    "\n",
    "            for hour_ind in range(24):\n",
    "            # for hour_ind in range(4):\n",
    "                datetime_ind = datetime.datetime(today.year, today.month, today.day, hour_ind)\n",
    "                print(str(datetime_ind))\n",
    "\n",
    "                air_pol_datetime_ind_df = air_pol_2013.loc[air_pol_2013.datetime == datetime_ind]\n",
    "                air_pol_datetime_ind_df.index = range(len(air_pol_datetime_ind_df))\n",
    "\n",
    "                air_pol_datetime_ind_df_geoinfo = pd.merge(air_pol_datetime_ind_df,site_info_dropna.loc[:,['stationName', 'geometry']],how='left',left_on='측정소명',right_on='stationName')\n",
    "                air_pol_datetime_ind_df_geoinfo = air_pol_datetime_ind_df_geoinfo.loc[~air_pol_datetime_ind_df_geoinfo.stationName.isna()]\n",
    "                air_pol_datetime_ind_df_geoinfo.index = range(len(air_pol_datetime_ind_df_geoinfo))\n",
    "                air_pol_datetime_ind_df_geoinfo = gpd.GeoDataFrame(air_pol_datetime_ind_df_geoinfo, geometry='geometry')\n",
    "                air_pol_datetime_ind_df_geoinfo = air_pol_datetime_ind_df_geoinfo.fillna(0)\n",
    "                air_pol_datetime_ind_df_geoinfo = air_pol_datetime_ind_df_geoinfo.loc[~(air_pol_datetime_ind_df_geoinfo.PM10 == -999)]  # 값이 -999찍혀있을때가 있음 기기오작동으로보고 제거\n",
    "                air_pol_datetime_ind_df_geoinfo.index = range(len(air_pol_datetime_ind_df_geoinfo))\n",
    "\n",
    "                # out_grid = make_geocube(vector_data=test_data, measurements=[\"습도(%)\"], geom=geom,resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "                out_grid = make_geocube(vector_data=air_pol_datetime_ind_df_geoinfo, measurements=[\"PM10\"],resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "                out_grid[\"PM10\"].rio.to_raster(\"rasterized_air_pol.tif\")\n",
    "\n",
    "\n",
    "                dst_crs = projout\n",
    "                with rasterio.open(os.path.join(path,\"rasterized_air_pol.tif\")) as src:\n",
    "                    # print(src.width, src.height, *src.bounds,)\n",
    "                    transform, width, height = calculate_default_transform(\n",
    "                                    src.crs, \n",
    "                                    dst_crs, \n",
    "                                    src.width, \n",
    "                                    src.height, \n",
    "                                    *src.bounds)\n",
    "                \n",
    "                    kwargs = src.meta.copy()\n",
    "                    kwargs.update({\n",
    "                        'crs': dst_crs,\n",
    "                        'transform': transform,\n",
    "                        'width': width,\n",
    "                        'height': height\n",
    "                    })\n",
    "\n",
    "                    with rasterio.open(os.path.join(path,\"rasterized_air_pol_lcc.tif\"), 'w', **kwargs) as dst:\n",
    "                            \n",
    "                            for i in range(1, src.count + 1):\n",
    "                                reproject(\n",
    "                                    source=rasterio.band(src, i),\n",
    "                                    destination=rasterio.band(dst, i),\n",
    "                                    src_transform=src.transform,\n",
    "                                    src_crs=src.crs,\n",
    "                                    dst_transform=transform,\n",
    "                                    dst_crs=dst_crs,\n",
    "                                    resampling=Resampling.nearest)\n",
    "\n",
    "            \n",
    "\n",
    "                with rasterio.open(os.path.join(path,\"base_lcc_lcc.tif\")) as src, rasterio.open(os.path.join(path,\"rasterized_air_pol_lcc.tif\")) as src2:\n",
    "                    raster_list = [src, src2]\n",
    "                    # print(src.read(1).shape, src2.read(1).shape,)\n",
    "                    mosaic, output = merge(raster_list)\n",
    "\n",
    "                    output_meta = src2.meta.copy()\n",
    "                    output_meta.update(\n",
    "                        {\"driver\": \"GTiff\",\n",
    "                            \"height\": mosaic.shape[1],\n",
    "                            \"width\": mosaic.shape[2],\n",
    "                            \"transform\": output,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    with rasterio.open(os.path.join(path,\"rasterized_air_pol_lcc_final.tif\"), \"w\", **output_meta) as m:\n",
    "                        m.write(mosaic)\n",
    "\n",
    "                with rasterio.open(os.path.join(path,\"rasterized_air_pol_lcc_final.tif\")) as src:\n",
    "                    air_pol_pm10_arr = src.read(1)\n",
    "                    air_pol_pm10_arr = air_pol_pm10_arr.reshape(1,82,67,1)\n",
    "                    # print(air_pol_pm10_arr.shape)\n",
    "                em_df_ind_df = em_df.loc[em_df.datetime == datetime_ind]\n",
    "                em_df_ind_df.index = range(len(em_df_ind_df))\n",
    "                em_df_ind_df_geoinfo = pd.merge(em_df_ind_df,em_point_gdf.loc[:,['지점', 'geometry']],how='left',on = '지점')\n",
    "\n",
    "                em_df_ind_df_geoinfo = em_df_ind_df_geoinfo.loc[~em_df_ind_df_geoinfo.geometry.isna()]\n",
    "                em_df_ind_df_geoinfo.index = range(len(em_df_ind_df_geoinfo))\n",
    "                em_df_ind_df_geoinfo = gpd.GeoDataFrame(em_df_ind_df_geoinfo, geometry='geometry')\n",
    "                em_df_ind_df_geoinfo = em_df_ind_df_geoinfo.fillna(0)\n",
    "\n",
    "\n",
    "                # out_grid = make_geocube(vector_data=test_data, measurements=[\"습도(%)\"], geom=geom,resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "\n",
    "                em_arr_list = []\n",
    "                for col_name in col_list:\n",
    "                    \n",
    "                    out_grid = make_geocube(vector_data=em_df_ind_df_geoinfo, measurements=[col_name],resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "                    out_grid[col_name].rio.to_raster(\"rasterized_em.tif\")\n",
    "\n",
    "                    dst_crs = projout\n",
    "                    with rasterio.open(os.path.join(path,\"rasterized_em.tif\")) as src:\n",
    "                        # print(src.count)\n",
    "                        transform, width, height = calculate_default_transform(\n",
    "                                        src.crs, \n",
    "                                        dst_crs, \n",
    "                                        src.width, \n",
    "                                        src.height, \n",
    "                                        *src.bounds)\n",
    "                    \n",
    "                        kwargs = src.meta.copy()\n",
    "                        kwargs.update({\n",
    "                            'crs': dst_crs,\n",
    "                            'transform': transform,\n",
    "                            'width': width,\n",
    "                            'height': height\n",
    "                        })\n",
    "\n",
    "                        with rasterio.open(os.path.join(path,\"rasterized_em_lcc.tif\"), 'w', **kwargs) as dst:\n",
    "                                \n",
    "                                for i in range(1, src.count + 1):\n",
    "                                    reproject(\n",
    "                                        source=rasterio.band(src, i),\n",
    "                                        destination=rasterio.band(dst, i),\n",
    "                                        src_transform=src.transform,\n",
    "                                        src_crs=src.crs,\n",
    "                                        dst_transform=transform,\n",
    "                                        dst_crs=dst_crs,\n",
    "                                        resampling=Resampling.nearest)\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "                    with rasterio.open(os.path.join(path,\"base_lcc_lcc.tif\")) as src, rasterio.open(os.path.join(path,\"rasterized_em_lcc.tif\")) as src2:\n",
    "                        raster_list = [src, src2]\n",
    "                        # print(src.read(1).shape, src2.read(1).shape,)\n",
    "                        mosaic, output = merge(raster_list)\n",
    "\n",
    "                        output_meta = src2.meta.copy()\n",
    "                        output_meta.update(\n",
    "                            {\"driver\": \"GTiff\",\n",
    "                                \"height\": mosaic.shape[1],\n",
    "                                \"width\": mosaic.shape[2],\n",
    "                                \"transform\": output,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                        with rasterio.open(os.path.join(path,\"rasterized_em_lcc_final.tif\"), \"w\", **output_meta) as m:\n",
    "                            m.write(mosaic)\n",
    "\n",
    "                    with rasterio.open(os.path.join(path,\"rasterized_em_lcc_final.tif\")) as src:\n",
    "                    \n",
    "                        em_arr = src.read(1)\n",
    "                        em_arr = em_arr.reshape(1,82,67,1)\n",
    "                        em_arr_list.append(em_arr)\n",
    "\n",
    "                em_arr_map = np.concatenate(em_arr_list,axis=3)\n",
    "\n",
    "                weather_t = em_arr_map[:1].tobytes()\n",
    "                air_q_t = air_pol_pm10_arr[:1].tobytes()\n",
    "                cmaq_t = day_concen_pm10[hour_ind:hour_ind+1].tobytes()\n",
    "                smoke_t = day_smoke_allval[hour_ind:hour_ind+1].tobytes()\n",
    "\n",
    "                example = tf.train.Example(\n",
    "                    features=tf.train.Features(\n",
    "                        feature={\n",
    "                            'CMAQ_t': _bytes_feature(cmaq_t),\n",
    "                            'SMOKE_t': _bytes_feature(smoke_t),\n",
    "                            'air_quality_monitoring_t': _bytes_feature(air_q_t),   \n",
    "                            'weather_monitoring_t': _bytes_feature(weather_t),\n",
    "                            'year': _bytes_feature(np.array(today.year - 2000).reshape(1,-1).tobytes()), \n",
    "                            'month': _bytes_feature(np.array(today.month).reshape(1,-1).tobytes()), \n",
    "                            'day': _bytes_feature(np.array(today.day).reshape(1,-1).tobytes()), \n",
    "                            'hour': _bytes_feature(np.array(hour_ind).reshape(1,-1).tobytes()), \n",
    "\n",
    "                        }\n",
    "                        )\n",
    "                    )\n",
    "                writer_image.write(example.SerializeToString())\n",
    "        \n",
    "    writer_image.close()\n",
    "\n",
    "    shutil.rmtree(os.path.join(\"e:\",\"dataset_record\",\"Concentration\",f\"RSM_{s_num}\"))\n",
    "    shutil.rmtree(os.path.join(\"e:\",\"dataset_record\",\"Emission\",f\"RSM_{s_num}\"))\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 최신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/workspace'\n",
    "data_path = os.path.join(path,'cmaqProjectdata')\n",
    "record_path = os.path.join(data_path,'dataset_record')\n",
    "proj_path = os.path.join(path,'repos','cmaqProject')\n",
    "band_depth = 15 # 기상자료에 들어가는 밴드뎁스 상황에따라 바꿔주기\n",
    "col_list = ['기온(°C)', '강수량(mm)', '풍속(m/s)', '풍향(16방위)', '습도(%)', '증기압(hPa)', '이슬점온도(°C)', '현지기압(hPa)', '해면기압(hPa)', '일조(hr)', '일사(MJ/m2)', '적설(cm)', '3시간신적설(cm)', '전운량(10분위)', '중하층운량(10분위)',]\n",
    "pm_10_cal = \"(1.0*ASO4J[1])+(1.0*ASO4I[1])+(1.0*ANH4J[1])+(1.0*ANH4I[1])+(1.0*ANO3J[1])+(1.0*ANO3I[1])+(1.0*AALKJ[1])+(1.0*AXYL1J[1])+(1.0*AXYL2J[1])+(1.0*AXYL3J[1])+(1.0*ATOL1J[1])+(1.0*ATOL2J[1])+(1.0*ATOL3J[1])+(1.0*ABNZ1J[1])+(1.0*ABNZ2J[1])+(1.0*ABNZ3J[1])+(1.0*ATRP1J[1])+(1.0*ATRP2J[1])+(1.0*AISO1J[1])+(1.0*AISO2J[1])+(1.0*AISO3J[1])+(1.0*ASQTJ[1])+(1.0*AORGCJ[1])+(1.0*AORGPAJ[1])+(1.0*AORGPAI[1])+(1.0*AECJ[1])+(1.0*AECI[1])+(1.0*A25J[1])+(1.0*ANAJ[1])+(1.0*ACLJ[1])+(1.0*ACLI[1])+(1.0*AOLGAJ[1])+(1.0*AOLGBJ[1])+(1.0*ACORS[1])+(1.0*ASOIL[1])+(1.0*ANAK[1])+(1.0*ACLK[1])+(1.0*ASO4K[1])+(1.0*ANH4K[1])+(1.0*ANO3K[1])\"\n",
    "pm_10_chem_list = [chem[5:-4] for chem in pm_10_cal.split(\"+\")]\n",
    "\n",
    "\n",
    "projout = '+proj=lcc +lat_1=30 +lat_2=60 +lon_1=126 +lat_0=38 +lon_0=126 +ellps=GRS80 +units=m'\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "concentration_path_list = np.array(glob(os.path.join(data_path, \"extract\",\"concentration\", \"*\")))\n",
    "emission_path_list = np.array(glob(os.path.join(data_path, \"extract\",\"emission\", \"*\")))\n",
    "\n",
    "senario_list = list(set([path.split(\"/\")[-1] for path in concentration_path_list]) & set([path.split(\"/\")[-1] for path in emission_path_list]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/pyproj/crs/crs.py:141: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    }
   ],
   "source": [
    "# 기상측정망, 대기질측정망 메타정보 정리\n",
    "em_meta = pd.read_csv(glob(os.path.join(data_path,\"시간단위_기상자료개방포털\",\"rawdata\",\"meta\",\"*.csv\",))[0],encoding='cp949')\n",
    "geo_point = []\n",
    "for i in range(len(em_meta)):\n",
    "    x,y = em_meta.loc[i,'경도'], em_meta.loc[i,'위도']\n",
    "    geo_point.append(Point(x,y))\n",
    "    \n",
    "\n",
    "em_meta['geometry'] = geo_point\n",
    "\n",
    "em_point_gdf = gpd.GeoDataFrame(em_meta, geometry= 'geometry')\n",
    "em_point_gdf.crs = {'init':'epsg:4326'}\n",
    "\n",
    "url = 'http://apis.data.go.kr/B552584/MsrstnInfoInqireSvc/getMsrstnList'\n",
    "key = \"k5wXUhoJHwee1cncQCBmm81YbQ+exttb0vdJcyF5GuGJn0mbGBNNL/ER2VfkrJMlExfc+FZjPeRuOM2bvgDYyQ==\"\n",
    "\n",
    "# params ={'serviceKey' : key, 'addr': '서울', 'stationName': '종로구', 'pageNo': 1, 'numOfRows': 10,'returnType': 'json'}\n",
    "params ={'serviceKey' : key, 'pageNo': 1, 'numOfRows': 640,'returnType': 'json'}\n",
    "response = requests.get(url, params=params, verify=False)\n",
    "\n",
    "data_dic = response.json()\n",
    "site_info = pd.DataFrame(data_dic['response']['body']['items'])\n",
    "\n",
    "point_list = []\n",
    "for i in range(len(site_info)):\n",
    "    try:\n",
    "        point_list.append(Point(float(site_info.dmY[i]), float(site_info.dmX[i])))\n",
    "    except:\n",
    "        point_list.append(None)\n",
    "\n",
    "site_info.loc[:,'geometry'] = point_list\n",
    "site_info_dropna = site_info.loc[~site_info.isna().dmX.values]\n",
    "\n",
    "site_info_dropna = gpd.GeoDataFrame(site_info_dropna, geometry = 'geometry')\n",
    "site_info_dropna.crs = em_point_gdf.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "from rasterio.merge import merge\n",
    "import tensorflow as tf\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2766000 entries, 0 to 699935\n",
      "Data columns (total 10 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   지역      object \n",
      " 1   측정소명    object \n",
      " 2   측정소코드   int64  \n",
      " 3   측정일시    int64  \n",
      " 4   SO2     float64\n",
      " 5   CO      float64\n",
      " 6   O3      float64\n",
      " 7   NO2     float64\n",
      " 8   PM10    int64  \n",
      " 9   주소      object \n",
      "dtypes: float64(4), int64(3), object(3)\n",
      "memory usage: 232.1+ MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 262839 entries, 0 to 8727\n",
      "Data columns (total 27 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   지점             262839 non-null  int64  \n",
      " 1   일시             262839 non-null  object \n",
      " 2   기온(°C)         262609 non-null  float64\n",
      " 3   강수량(mm)        19578 non-null   float64\n",
      " 4   풍속(m/s)        262522 non-null  float64\n",
      " 5   풍향(16방위)       262520 non-null  float64\n",
      " 6   습도(%)          262609 non-null  float64\n",
      " 7   증기압(hPa)       262610 non-null  float64\n",
      " 8   이슬점온도(°C)      262608 non-null  float64\n",
      " 9   현지기압(hPa)      262625 non-null  float64\n",
      " 10  해면기압(hPa)      262608 non-null  float64\n",
      " 11  일조(hr)         143715 non-null  float64\n",
      " 12  일사(MJ/m2)      47839 non-null   float64\n",
      " 13  적설(cm)         4110 non-null    float64\n",
      " 14  3시간신적설(cm)     186 non-null     float64\n",
      " 15  전운량(10분위)      20597 non-null   float64\n",
      " 16  중하층운량(10분위)    20597 non-null   float64\n",
      " 17  운형(운형약어)       14637 non-null   object \n",
      " 18  최저운고(100m )    12730 non-null   float64\n",
      " 19  시정(10m)        20605 non-null   float64\n",
      " 20  지면상태(지면상태코드)   4383 non-null    float64\n",
      " 21  현상번호(국내식)      7526 non-null    float64\n",
      " 22  지면온도(°C)       262580 non-null  float64\n",
      " 23  5cm 지중온도(°C)   96236 non-null   float64\n",
      " 24  10cm 지중온도(°C)  95826 non-null   float64\n",
      " 25  20cm 지중온도(°C)  96237 non-null   float64\n",
      " 26  30cm 지중온도(°C)  96237 non-null   float64\n",
      "dtypes: float64(24), int64(1), object(2)\n",
      "memory usage: 56.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# 대기질자료 불러오기\n",
    "airpolutant_monitoring_2013_list = glob(os.path.join(data_path,\"시간단위대기질자료\",\"rawdata\",\"extract\",\"2013*\",))\n",
    "airpolutant_monitoring_2013_list\n",
    "data_list = []\n",
    "for i in airpolutant_monitoring_2013_list:\n",
    "    temp_data = pd.read_excel(i)\n",
    "    data_list.append(temp_data)\n",
    "air_pol_2013 = pd.concat(data_list)\n",
    "air_pol_2013.info()\n",
    "\n",
    "#기상자료 불러오기\n",
    "em_dataset_path_list = glob(os.path.join(data_path,\"시간단위_기상자료개방포털\",\"rawdata\",\"extract\",\"*.csv\",))\n",
    "em_dataset_list = [pd.read_csv(path, encoding='cp949') for path in em_dataset_path_list]\n",
    "em_df = pd.concat(em_dataset_list, axis = 0)\n",
    "em_df.info()\n",
    "datetime_airpol = [datetime.datetime(int(date[:4]),int(date[4:6]),int(date[6:8]),int(date[8:] if date[8:] !='24' else '0')) for date in air_pol_2013.측정일시.values.astype(str)]\n",
    "air_pol_2013.loc[:,'datetime'] = datetime_airpol\n",
    "em_df.loc[:,'datetime'] = pd.to_datetime(em_df.일시)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 83\n"
     ]
    }
   ],
   "source": [
    "# out_grid = make_geocube(vector_data=test_data, measurements=[\"습도(%)\"], geom=geom,resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "x_m = list(range(-180000,-180000 + 9000 * 68, 9000))\n",
    "y_m = list(range(-585000,-585000 + 9000 * 83, 9000))\n",
    "\n",
    "print(len(x_m), len(y_m))\n",
    "\n",
    "grid_points = []\n",
    "for x_i in x_m:\n",
    "    for y_i in y_m:\n",
    "        grid_points.append(Point(x_i,y_i))\n",
    "\n",
    "grid_data = pd.DataFrame(grid_points, columns=['geometry'])\n",
    "\n",
    "grid_data = gpd.GeoDataFrame(grid_data, geometry='geometry')\n",
    "grid_data.crs = em_point_gdf.to_crs(projout).crs\n",
    "grid_data.loc[:,'x_m'] = grid_data.geometry.x\n",
    "grid_data.loc[:,'y_m'] = grid_data.geometry.y\n",
    "grid_data.loc[:,'value'] = 0\n",
    "\n",
    "out_grid = make_geocube(vector_data=grid_data, measurements=[\"value\"],resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "out_grid[\"value\"].rio.to_raster(os.path.join(record_path,\"base_lcc.tif\"))\n",
    "# 레스터 좌표변환\n",
    "# 5181로 변환하면 좌표들 약간 틀어짐\n",
    "# lcc로 처리 해야함\n",
    "from rasterio.warp import calculate_default_transform, reproject, Resampling\n",
    "# dst_crs = 'epsg: 5181'\n",
    "dst_crs = '+proj=lcc +lat_1=30 +lat_2=60 +lon_1=126 +lat_0=38 +lon_0=126 +ellps=GRS80 +units=m'\n",
    "\n",
    "with rasterio.open(os.path.join(record_path,\"base_lcc.tif\")) as src:\n",
    "\n",
    "    transform, width, height = calculate_default_transform(\n",
    "                    src.crs, \n",
    "                    dst_crs, \n",
    "                    src.width, \n",
    "                    src.height, \n",
    "                    *src.bounds)\n",
    "   \n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height\n",
    "    })\n",
    "\n",
    "    with rasterio.open(os.path.join(record_path,\"base_lcc_lcc.tif\"), 'w', **kwargs) as dst:\n",
    "            \n",
    "            for i in range(1, src.count + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, i),\n",
    "                    destination=rasterio.band(dst, i),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    resampling=Resampling.nearest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 83\n"
     ]
    }
   ],
   "source": [
    "##################밴드 뎁스 레스터로 만들기( 머지할때 필요 )\n",
    "\n",
    "# out_grid = make_geocube(vector_data=test_data, measurements=[\"습도(%)\"], geom=geom,resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "x_m = list(range(-180000,-180000 + 9000 * 68, 9000))\n",
    "y_m = list(range(-585000,-585000 + 9000 * 83, 9000))\n",
    "\n",
    "print(len(x_m), len(y_m))\n",
    "\n",
    "grid_points = []\n",
    "for x_i in x_m:\n",
    "    for y_i in y_m:\n",
    "        grid_points.append(Point(x_i,y_i))\n",
    "\n",
    "grid_data = pd.DataFrame(grid_points, columns=['geometry'])\n",
    "\n",
    "grid_data = gpd.GeoDataFrame(grid_data, geometry='geometry')\n",
    "grid_data.crs = em_point_gdf.to_crs(projout).crs\n",
    "grid_data.loc[:,'x_m'] = grid_data.geometry.x\n",
    "grid_data.loc[:,'y_m'] = grid_data.geometry.y\n",
    "grid_data.loc[:,'value'] = 0\n",
    "\n",
    "out_grid = make_geocube(vector_data=grid_data, measurements=[\"value\"],resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "out_grid[\"value\"].rio.to_raster(os.path.join(record_path,\"base_lcc.tif\"))\n",
    "# 레스터 좌표변환\n",
    "# 5181로 변환하면 좌표들 약간 틀어짐\n",
    "# lcc로 처리 해야함\n",
    "\n",
    "# dst_crs = 'epsg: 5181'\n",
    "dst_crs = '+proj=lcc +lat_1=30 +lat_2=60 +lon_1=126 +lat_0=38 +lon_0=126 +ellps=GRS80 +units=m'\n",
    "\n",
    "with rasterio.open(os.path.join(record_path,\"base_lcc.tif\")) as src:\n",
    "\n",
    "    transform, width, height = calculate_default_transform(\n",
    "                    src.crs, \n",
    "                    dst_crs, \n",
    "                    src.width, \n",
    "                    src.height, \n",
    "                    *src.bounds)\n",
    "   \n",
    "    kwargs = src.meta.copy()\n",
    "    kwargs.update({\n",
    "        'crs': dst_crs,\n",
    "        'transform': transform,\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'count': band_depth,\n",
    "        \n",
    "    })\n",
    "\n",
    "    with rasterio.open(os.path.join(record_path,f\"base_lcc_lcc_{band_depth}depth.tif\"), 'w', **kwargs) as dst:\n",
    "            \n",
    "            for i in range(1, band_depth + 1):\n",
    "                reproject(\n",
    "                    source=rasterio.band(src, 1),\n",
    "                    destination=rasterio.band(dst, 1),\n",
    "                    src_transform=src.transform,\n",
    "                    src_crs=src.crs,\n",
    "                    dst_transform=transform,\n",
    "                    dst_crs=dst_crs,\n",
    "                    resampling=Resampling.nearest)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* version1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in senario_list:\n",
    "\n",
    "    if i == 'RSM_1':\n",
    "        print(i, '건너뛰기')\n",
    "        continue\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    path_emis = emission_path_list[np.array([path.split(\"/\")[-1] for path in emission_path_list]) == i][0]\n",
    "    path_conc = concentration_path_list[np.array([path.split(\"/\")[-1] for path in concentration_path_list]) == i][0]\n",
    "    s_num = i.split(\"_\")[-1]\n",
    "    \n",
    "    # 날짜별 smoke, cmaq데이터셋 경로 정리\n",
    "    emis_list = glob(os.path.join(path_emis,\"*\"))         \n",
    "    concentration_list = glob(os.path.join(path_conc,\"*\"))           \n",
    "\n",
    "    emis_day_list = [os.path.split(path)[-1].split('.')[-5] for path in emis_list]\n",
    "    concentration_day_list = [os.path.split(path)[-1].split('.')[-2] for path in concentration_list]\n",
    "\n",
    "    \n",
    "    concentration_day_list_datetime = []\n",
    "    for date in concentration_day_list:\n",
    "\n",
    "        start_date = datetime.date(int(date[:4]), 1, 1) + datetime.timedelta(-1)\n",
    "        d_day = int(date[4:])\n",
    "        target_date = start_date + datetime.timedelta(d_day)\n",
    "\n",
    "        concentration_day_list_datetime.append(target_date)\n",
    "\n",
    "    emis_day_list_datetime = []\n",
    "    for date in emis_day_list:\n",
    "        target_date = datetime.date(int(date[:4]), int(date[4:6]), int(date[6:]))\n",
    "        emis_day_list_datetime.append(target_date)\n",
    "\n",
    "    emis_info_df = pd.DataFrame()\n",
    "    emis_info_df.loc[:,['date']] = emis_day_list_datetime\n",
    "    emis_info_df.loc[:,['path']] = emis_list\n",
    "\n",
    "    concentration_info_df = pd.DataFrame()\n",
    "    concentration_info_df.loc[:,['date']] = concentration_day_list_datetime\n",
    "    concentration_info_df.loc[:,['path']] = concentration_list\n",
    "    concentration_info_df = concentration_info_df.sort_values('date')\n",
    "    concentration_info_df.index = range(len(concentration_info_df))\n",
    "\n",
    "    con_emis_info_merged_df = pd.merge(concentration_info_df, emis_info_df, how='left', on='date', suffixes=['_concentration', '_emission'])\n",
    "        \n",
    "    con_emis_info_merged_df_dropna = con_emis_info_merged_df.loc[~con_emis_info_merged_df.path_emission.isna(),]\n",
    "    con_emis_info_merged_df_dropna.index = range(len(con_emis_info_merged_df_dropna))\n",
    "\n",
    "    writer_image = tf.io.TFRecordWriter(os.path.join(record_path,f\"dataset_{s_num}.tfr\"))\n",
    "    print(os.path.join(record_path,f\"dataset_{s_num}.tfr\"))\n",
    "\n",
    "    for k in range(len(con_emis_info_merged_df_dropna)):\n",
    "    # for i in range(len(con_emis_info_merged_df_dropna))[:1]:\n",
    "    \n",
    "        today = con_emis_info_merged_df_dropna.loc[k].date\n",
    "        print(today)\n",
    "        # 해당날짜의 데이터셋 불러오기\n",
    "        with Dataset(con_emis_info_merged_df_dropna.loc[k].path_concentration, 'r') as concen_data, Dataset(con_emis_info_merged_df_dropna.loc[k].path_emission, 'r') as emis_data:\n",
    "\n",
    "            # concen_data = Dataset(con_emis_info_merged_df_dropna.loc[k].path_concentration, 'r')\n",
    "            # emis_data = Dataset(con_emis_info_merged_df_dropna.loc[k].path_emission, 'r')\n",
    "\n",
    "            # 해당날짜의 관련변수 합으로 pm10 CMAQ array형성\n",
    "            pm10_chemlist = [np.array(concen_data.variables[chem]) for chem in pm_10_chem_list]\n",
    "            day_concen_pm10 = np.sum(pm10_chemlist, axis=0)\n",
    "            day_concen_pm10 = day_concen_pm10.reshape(day_concen_pm10.shape[0],day_concen_pm10.shape[2],day_concen_pm10.shape[3],-1)\n",
    "\n",
    "            # 해당날짜의 smoke 모든변수 array 형성, 연직방향으로는 맨 밑레이어만 사용\n",
    "            smoke_chem_list = list(set(emis_data.variables.keys()) - set(['TFLAG']))\n",
    "            # smoke_chem_arr_list = [np.array(emis_data.variables[chem])[:,0:1,:,:].reshape(25,82,67,-1) for chem in smoke_chem_list]\n",
    "            smoke_chem_arr_list = [emis_data[chem][:,0,:,:].reshape(25,82,67,-1) for chem in smoke_chem_list]\n",
    "            day_smoke_allval = np.concatenate(smoke_chem_arr_list, axis=3)\n",
    "            day_smoke_allval = day_smoke_allval[:24]\n",
    "\n",
    "            print('CMAQ_PM10 데이터셋: ',day_concen_pm10.shape, 'SMOKE_모든변수 데이터셋: ',day_smoke_allval.shape)\n",
    "\n",
    "            for hour_ind in range(24):\n",
    "            # for hour_ind in range(4):\n",
    "                datetime_ind = datetime.datetime(today.year, today.month, today.day, hour_ind)\n",
    "                print(str(datetime_ind))\n",
    "\n",
    "                air_pol_datetime_ind_df = air_pol_2013.loc[air_pol_2013.datetime == datetime_ind]\n",
    "                air_pol_datetime_ind_df.index = range(len(air_pol_datetime_ind_df))\n",
    "\n",
    "                air_pol_datetime_ind_df_geoinfo = pd.merge(air_pol_datetime_ind_df,site_info_dropna.loc[:,['stationName', 'geometry']],how='left',left_on='측정소명',right_on='stationName')\n",
    "                air_pol_datetime_ind_df_geoinfo = air_pol_datetime_ind_df_geoinfo.loc[~air_pol_datetime_ind_df_geoinfo.stationName.isna()]\n",
    "                air_pol_datetime_ind_df_geoinfo.index = range(len(air_pol_datetime_ind_df_geoinfo))\n",
    "                air_pol_datetime_ind_df_geoinfo = gpd.GeoDataFrame(air_pol_datetime_ind_df_geoinfo, geometry='geometry')\n",
    "                air_pol_datetime_ind_df_geoinfo = air_pol_datetime_ind_df_geoinfo.fillna(0)\n",
    "                air_pol_datetime_ind_df_geoinfo = air_pol_datetime_ind_df_geoinfo.loc[~(air_pol_datetime_ind_df_geoinfo.PM10 == -999)]  # 값이 -999찍혀있을때가 있음 기기오작동으로보고 제거\n",
    "                air_pol_datetime_ind_df_geoinfo.index = range(len(air_pol_datetime_ind_df_geoinfo))\n",
    "\n",
    "                # out_grid = make_geocube(vector_data=test_data, measurements=[\"습도(%)\"], geom=geom,resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "                out_grid = make_geocube(vector_data=air_pol_datetime_ind_df_geoinfo, measurements=[\"PM10\"],resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "                out_grid[\"PM10\"].rio.to_raster(os.path.join(record_path,\"rasterized_air_pol.tif\"))\n",
    "\n",
    "\n",
    "                dst_crs = projout\n",
    "                with rasterio.open(os.path.join(record_path,\"rasterized_air_pol.tif\")) as src:\n",
    "                    # print(src.width, src.height, *src.bounds,)\n",
    "                    transform, width, height = calculate_default_transform(\n",
    "                                    src.crs, \n",
    "                                    dst_crs, \n",
    "                                    src.width, \n",
    "                                    src.height, \n",
    "                                    *src.bounds)\n",
    "                \n",
    "                    kwargs = src.meta.copy()\n",
    "                    kwargs.update({\n",
    "                        'crs': dst_crs,\n",
    "                        'transform': transform,\n",
    "                        'width': width,\n",
    "                        'height': height\n",
    "                    })\n",
    "\n",
    "                    with rasterio.open(os.path.join(record_path,\"rasterized_air_pol_lcc.tif\"), 'w', **kwargs) as dst:\n",
    "                            \n",
    "                            for i in range(1, src.count + 1):\n",
    "                                reproject(\n",
    "                                    source=rasterio.band(src, i),\n",
    "                                    destination=rasterio.band(dst, i),\n",
    "                                    src_transform=src.transform,\n",
    "                                    src_crs=src.crs,\n",
    "                                    dst_transform=transform,\n",
    "                                    dst_crs=dst_crs,\n",
    "                                    resampling=Resampling.nearest)\n",
    "\n",
    "            \n",
    "\n",
    "                with rasterio.open(os.path.join(record_path,\"base_lcc_lcc.tif\")) as src, rasterio.open(os.path.join(record_path,\"rasterized_air_pol_lcc.tif\")) as src2:\n",
    "                    raster_list = [src, src2]\n",
    "                    # print(src.read(1).shape, src2.read(1).shape,)\n",
    "                    mosaic, output = merge(raster_list)\n",
    "\n",
    "                    output_meta = src2.meta.copy()\n",
    "                    output_meta.update(\n",
    "                        {\"driver\": \"GTiff\",\n",
    "                            \"height\": mosaic.shape[1],\n",
    "                            \"width\": mosaic.shape[2],\n",
    "                            \"transform\": output,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    with rasterio.open(os.path.join(record_path,\"rasterized_air_pol_lcc_final.tif\"), \"w\", **output_meta) as m:\n",
    "                        m.write(mosaic)\n",
    "\n",
    "                with rasterio.open(os.path.join(record_path,\"rasterized_air_pol_lcc_final.tif\")) as src:\n",
    "                    air_pol_pm10_arr = src.read(1)\n",
    "                    air_pol_pm10_arr = air_pol_pm10_arr.reshape(1,82,67,1)\n",
    "                    # print(air_pol_pm10_arr.shape)\n",
    "                em_df_ind_df = em_df.loc[em_df.datetime == datetime_ind]\n",
    "                em_df_ind_df.index = range(len(em_df_ind_df))\n",
    "                em_df_ind_df_geoinfo = pd.merge(em_df_ind_df,em_point_gdf.loc[:,['지점', 'geometry']],how='left',on = '지점')\n",
    "\n",
    "                em_df_ind_df_geoinfo = em_df_ind_df_geoinfo.loc[~em_df_ind_df_geoinfo.geometry.isna()]\n",
    "                em_df_ind_df_geoinfo.index = range(len(em_df_ind_df_geoinfo))\n",
    "                em_df_ind_df_geoinfo = gpd.GeoDataFrame(em_df_ind_df_geoinfo, geometry='geometry')\n",
    "                em_df_ind_df_geoinfo = em_df_ind_df_geoinfo.fillna(0)\n",
    "\n",
    "\n",
    "                out_grid = make_geocube(vector_data=em_df_ind_df_geoinfo, measurements=col_list,resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "                # out_grid[col_name].rio.to_raster(os.path.join(record_path,\"rasterized_em.tif\"))\n",
    "                out_grid.rio.to_raster(os.path.join(record_path,\"rasterized_em.tif\"))\n",
    "                with rasterio.open(os.path.join(record_path,\"rasterized_em.tif\")) as src:\n",
    "                        # print(src.count)\n",
    "                        transform, width, height = calculate_default_transform(\n",
    "                                        src.crs, \n",
    "                                        dst_crs, \n",
    "                                        src.width, \n",
    "                                        src.height, \n",
    "                                        *src.bounds)\n",
    "                    \n",
    "                        kwargs = src.meta.copy()\n",
    "                        kwargs.update({\n",
    "                            'crs': dst_crs,\n",
    "                            'transform': transform,\n",
    "                            'width': width,\n",
    "                            'height': height\n",
    "                        })\n",
    "\n",
    "                    \n",
    "\n",
    "                        with rasterio.open(os.path.join(record_path,\"rasterized_em_lcc.tif\"), 'w', **kwargs) as dst:\n",
    "\n",
    "                            for i in range(1, src.count + 1):\n",
    "                                \n",
    "                                reproject(\n",
    "                                    source=rasterio.band(src, i),\n",
    "                                    destination=rasterio.band(dst, i),\n",
    "                                    src_transform=src.transform,\n",
    "                                    src_crs=src.crs,\n",
    "                                    dst_transform=transform,\n",
    "                                    dst_crs=dst_crs,\n",
    "                                    resampling=Resampling.nearest)\n",
    "\n",
    "                with rasterio.open(os.path.join(record_path,f\"base_lcc_lcc_{band_depth}depth.tif\")) as src, rasterio.open(os.path.join(record_path,\"rasterized_em_lcc.tif\")) as src2:\n",
    "                        raster_list = [src, src2]\n",
    "                        # print(src.count, src2.count,)\n",
    "                        mosaic, output = merge(raster_list,)\n",
    "                        \n",
    "                        output_meta = src2.meta.copy()\n",
    "                        output_meta.update(\n",
    "                            {\"driver\": \"GTiff\",\n",
    "                                \"height\": mosaic.shape[1],\n",
    "                                \"width\": mosaic.shape[2],\n",
    "                                \"transform\": output,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                        with rasterio.open(os.path.join(record_path,\"rasterized_em_lcc_final.tif\"), \"w\", **output_meta) as m:\n",
    "                            m.write(mosaic)\n",
    "\n",
    "                \n",
    "                with rasterio.open(os.path.join(record_path,\"rasterized_em_lcc_final.tif\")) as src:\n",
    "\n",
    "                    em_arr_allband = src.read()\n",
    "                    em_arr_map = em_arr_allband.reshape(1,82,67,-1)\n",
    "\n",
    "                weather_t = em_arr_map[:1].tobytes()\n",
    "                air_q_t = air_pol_pm10_arr[:1].tobytes()\n",
    "                cmaq_t = day_concen_pm10[hour_ind:hour_ind+1].tobytes()\n",
    "                smoke_t = day_smoke_allval[hour_ind:hour_ind+1].tobytes()\n",
    "\n",
    "                example = tf.train.Example(\n",
    "                    features=tf.train.Features(\n",
    "                        feature={\n",
    "                            'CMAQ_t': _bytes_feature(cmaq_t),\n",
    "                            'SMOKE_t': _bytes_feature(smoke_t),\n",
    "                            'air_quality_monitoring_t': _bytes_feature(air_q_t),   \n",
    "                            'weather_monitoring_t': _bytes_feature(weather_t),\n",
    "                            'year': _bytes_feature(np.array(today.year - 2000).reshape(1,-1).tobytes()), \n",
    "                            'month': _bytes_feature(np.array(today.month).reshape(1,-1).tobytes()), \n",
    "                            'day': _bytes_feature(np.array(today.day).reshape(1,-1).tobytes()), \n",
    "                            'hour': _bytes_feature(np.array(hour_ind).reshape(1,-1).tobytes()), \n",
    "\n",
    "                        }\n",
    "                        )\n",
    "                    )\n",
    "                writer_image.write(example.SerializeToString())\n",
    "        \n",
    "    writer_image.close()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* version2\n",
    "* xr 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSM_89\n",
      "/home/workspace/cmaqProjectdata/dataset_record/dataset_89.tfr\n",
      "2013-03-22\n",
      "CMAQ_PM10 데이터셋:  (24, 82, 67, 1) SMOKE_모든변수 데이터셋:  (24, 82, 67, 45)\n",
      "2013-03-22 00:00:00\n",
      "2013-03-22 01:00:00\n",
      "2013-03-22 02:00:00\n",
      "2013-03-22 03:00:00\n",
      "2013-03-22 04:00:00\n",
      "2013-03-22 05:00:00\n",
      "2013-03-22 06:00:00\n",
      "2013-03-22 07:00:00\n",
      "2013-03-22 08:00:00\n",
      "2013-03-22 09:00:00\n",
      "2013-03-22 10:00:00\n",
      "2013-03-22 11:00:00\n",
      "2013-03-22 12:00:00\n",
      "2013-03-22 13:00:00\n",
      "2013-03-22 14:00:00\n",
      "2013-03-22 15:00:00\n",
      "2013-03-22 16:00:00\n",
      "2013-03-22 17:00:00\n",
      "2013-03-22 18:00:00\n",
      "2013-03-22 19:00:00\n",
      "2013-03-22 20:00:00\n",
      "2013-03-22 21:00:00\n",
      "2013-03-22 22:00:00\n",
      "2013-03-22 23:00:00\n",
      "2013-03-23\n",
      "CMAQ_PM10 데이터셋:  (24, 82, 67, 1) SMOKE_모든변수 데이터셋:  (24, 82, 67, 45)\n",
      "2013-03-23 00:00:00\n",
      "2013-03-23 01:00:00\n",
      "2013-03-23 02:00:00\n",
      "2013-03-23 03:00:00\n",
      "2013-03-23 04:00:00\n",
      "2013-03-23 05:00:00\n",
      "2013-03-23 06:00:00\n",
      "2013-03-23 07:00:00\n",
      "2013-03-23 08:00:00\n",
      "2013-03-23 09:00:00\n",
      "2013-03-23 10:00:00\n",
      "2013-03-23 11:00:00\n",
      "2013-03-23 12:00:00\n",
      "2013-03-23 13:00:00\n",
      "2013-03-23 14:00:00\n",
      "2013-03-23 15:00:00\n",
      "2013-03-23 16:00:00\n",
      "2013-03-23 17:00:00\n",
      "2013-03-23 18:00:00\n",
      "2013-03-23 19:00:00\n",
      "2013-03-23 20:00:00\n",
      "2013-03-23 21:00:00\n",
      "2013-03-23 22:00:00\n",
      "2013-03-23 23:00:00\n",
      "2013-03-24\n",
      "CMAQ_PM10 데이터셋:  (24, 82, 67, 1) SMOKE_모든변수 데이터셋:  (24, 82, 67, 45)\n",
      "2013-03-24 00:00:00\n",
      "2013-03-24 01:00:00\n",
      "2013-03-24 02:00:00\n",
      "2013-03-24 03:00:00\n",
      "2013-03-24 04:00:00\n",
      "2013-03-24 05:00:00\n",
      "2013-03-24 06:00:00\n",
      "2013-03-24 07:00:00\n",
      "2013-03-24 08:00:00\n",
      "2013-03-24 09:00:00\n",
      "2013-03-24 10:00:00\n",
      "2013-03-24 11:00:00\n",
      "2013-03-24 12:00:00\n",
      "2013-03-24 13:00:00\n",
      "2013-03-24 14:00:00\n",
      "2013-03-24 15:00:00\n",
      "2013-03-24 16:00:00\n",
      "2013-03-24 17:00:00\n",
      "2013-03-24 18:00:00\n",
      "2013-03-24 19:00:00\n",
      "2013-03-24 20:00:00\n",
      "2013-03-24 21:00:00\n",
      "2013-03-24 22:00:00\n",
      "2013-03-24 23:00:00\n",
      "2013-03-25\n",
      "CMAQ_PM10 데이터셋:  (24, 82, 67, 1) SMOKE_모든변수 데이터셋:  (24, 82, 67, 45)\n",
      "2013-03-25 00:00:00\n",
      "2013-03-25 01:00:00\n",
      "2013-03-25 02:00:00\n",
      "2013-03-25 03:00:00\n",
      "2013-03-25 04:00:00\n",
      "2013-03-25 05:00:00\n",
      "2013-03-25 06:00:00\n",
      "2013-03-25 07:00:00\n",
      "2013-03-25 08:00:00\n",
      "2013-03-25 09:00:00\n",
      "2013-03-25 10:00:00\n",
      "2013-03-25 11:00:00\n",
      "2013-03-25 12:00:00\n",
      "2013-03-25 13:00:00\n",
      "2013-03-25 14:00:00\n",
      "2013-03-25 15:00:00\n",
      "2013-03-25 16:00:00\n",
      "2013-03-25 17:00:00\n",
      "2013-03-25 18:00:00\n",
      "2013-03-25 19:00:00\n",
      "2013-03-25 20:00:00\n",
      "2013-03-25 21:00:00\n",
      "2013-03-25 22:00:00\n",
      "2013-03-25 23:00:00\n",
      "2013-03-26\n",
      "CMAQ_PM10 데이터셋:  (24, 82, 67, 1) SMOKE_모든변수 데이터셋:  (24, 82, 67, 45)\n",
      "2013-03-26 00:00:00\n",
      "2013-03-26 01:00:00\n",
      "2013-03-26 02:00:00\n",
      "2013-03-26 03:00:00\n",
      "2013-03-26 04:00:00\n",
      "2013-03-26 05:00:00\n",
      "2013-03-26 06:00:00\n",
      "2013-03-26 07:00:00\n",
      "2013-03-26 08:00:00\n",
      "2013-03-26 09:00:00\n",
      "2013-03-26 10:00:00\n",
      "2013-03-26 11:00:00\n",
      "2013-03-26 12:00:00\n",
      "2013-03-26 13:00:00\n",
      "2013-03-26 14:00:00\n",
      "2013-03-26 15:00:00\n",
      "2013-03-26 16:00:00\n",
      "2013-03-26 17:00:00\n",
      "2013-03-26 18:00:00\n",
      "2013-03-26 19:00:00\n",
      "2013-03-26 20:00:00\n",
      "2013-03-26 21:00:00\n",
      "2013-03-26 22:00:00\n",
      "2013-03-26 23:00:00\n",
      "2013-03-27\n",
      "CMAQ_PM10 데이터셋:  (24, 82, 67, 1) SMOKE_모든변수 데이터셋:  (24, 82, 67, 45)\n",
      "2013-03-27 00:00:00\n",
      "2013-03-27 01:00:00\n",
      "2013-03-27 02:00:00\n",
      "2013-03-27 03:00:00\n",
      "2013-03-27 04:00:00\n",
      "2013-03-27 05:00:00\n",
      "2013-03-27 06:00:00\n",
      "2013-03-27 07:00:00\n",
      "2013-03-27 08:00:00\n",
      "2013-03-27 09:00:00\n",
      "2013-03-27 10:00:00\n",
      "2013-03-27 11:00:00\n",
      "2013-03-27 12:00:00\n",
      "2013-03-27 13:00:00\n",
      "2013-03-27 14:00:00\n",
      "2013-03-27 15:00:00\n",
      "2013-03-27 16:00:00\n",
      "2013-03-27 17:00:00\n",
      "2013-03-27 18:00:00\n",
      "2013-03-27 19:00:00\n",
      "2013-03-27 20:00:00\n",
      "2013-03-27 21:00:00\n",
      "2013-03-27 22:00:00\n",
      "2013-03-27 23:00:00\n",
      "2013-03-28\n",
      "CMAQ_PM10 데이터셋:  (24, 82, 67, 1) SMOKE_모든변수 데이터셋:  (24, 82, 67, 45)\n",
      "2013-03-28 00:00:00\n",
      "2013-03-28 01:00:00\n",
      "2013-03-28 02:00:00\n",
      "2013-03-28 03:00:00\n",
      "2013-03-28 04:00:00\n",
      "2013-03-28 05:00:00\n",
      "2013-03-28 06:00:00\n",
      "2013-03-28 07:00:00\n",
      "2013-03-28 08:00:00\n",
      "2013-03-28 09:00:00\n",
      "2013-03-28 10:00:00\n",
      "2013-03-28 11:00:00\n",
      "2013-03-28 12:00:00\n",
      "2013-03-28 13:00:00\n",
      "2013-03-28 14:00:00\n",
      "2013-03-28 15:00:00\n",
      "2013-03-28 16:00:00\n",
      "2013-03-28 17:00:00\n",
      "2013-03-28 18:00:00\n",
      "2013-03-28 19:00:00\n",
      "2013-03-28 20:00:00\n",
      "2013-03-28 21:00:00\n",
      "2013-03-28 22:00:00\n",
      "2013-03-28 23:00:00\n",
      "2013-03-29\n",
      "CMAQ_PM10 데이터셋:  (24, 82, 67, 1) SMOKE_모든변수 데이터셋:  (24, 82, 67, 45)\n",
      "2013-03-29 00:00:00\n",
      "2013-03-29 01:00:00\n",
      "2013-03-29 02:00:00\n",
      "2013-03-29 03:00:00\n",
      "2013-03-29 04:00:00\n",
      "2013-03-29 05:00:00\n",
      "2013-03-29 06:00:00\n",
      "2013-03-29 07:00:00\n",
      "2013-03-29 08:00:00\n",
      "2013-03-29 09:00:00\n",
      "2013-03-29 10:00:00\n",
      "2013-03-29 11:00:00\n",
      "2013-03-29 12:00:00\n",
      "2013-03-29 13:00:00\n",
      "2013-03-29 14:00:00\n",
      "2013-03-29 15:00:00\n",
      "2013-03-29 16:00:00\n",
      "2013-03-29 17:00:00\n",
      "2013-03-29 18:00:00\n",
      "2013-03-29 19:00:00\n",
      "2013-03-29 20:00:00\n",
      "2013-03-29 21:00:00\n",
      "2013-03-29 22:00:00\n"
     ]
    }
   ],
   "source": [
    "## version2\n",
    "\n",
    "for i in senario_list:\n",
    "\n",
    "    if i == 'RSM_1':\n",
    "        print(i, '건너뛰기')\n",
    "        continue\n",
    "\n",
    "    print(i)\n",
    "\n",
    "    path_emis = emission_path_list[np.array([path.split(\"/\")[-1] for path in emission_path_list]) == i][0]\n",
    "    path_conc = concentration_path_list[np.array([path.split(\"/\")[-1] for path in concentration_path_list]) == i][0]\n",
    "    s_num = i.split(\"_\")[-1]\n",
    "    \n",
    "    # 날짜별 smoke, cmaq데이터셋 경로 정리\n",
    "    emis_list = glob(os.path.join(path_emis,\"*\"))         \n",
    "    concentration_list = glob(os.path.join(path_conc,\"*\"))           \n",
    "\n",
    "    emis_day_list = [os.path.split(path)[-1].split('.')[-5] for path in emis_list]\n",
    "    concentration_day_list = [os.path.split(path)[-1].split('.')[-2] for path in concentration_list]\n",
    "\n",
    "    \n",
    "    concentration_day_list_datetime = []\n",
    "    for date in concentration_day_list:\n",
    "\n",
    "        start_date = datetime.date(int(date[:4]), 1, 1) + datetime.timedelta(-1)\n",
    "        d_day = int(date[4:])\n",
    "        target_date = start_date + datetime.timedelta(d_day)\n",
    "\n",
    "        concentration_day_list_datetime.append(target_date)\n",
    "\n",
    "    emis_day_list_datetime = []\n",
    "    for date in emis_day_list:\n",
    "        target_date = datetime.date(int(date[:4]), int(date[4:6]), int(date[6:]))\n",
    "        emis_day_list_datetime.append(target_date)\n",
    "\n",
    "    emis_info_df = pd.DataFrame()\n",
    "    emis_info_df.loc[:,['date']] = emis_day_list_datetime\n",
    "    emis_info_df.loc[:,['path']] = emis_list\n",
    "\n",
    "    concentration_info_df = pd.DataFrame()\n",
    "    concentration_info_df.loc[:,['date']] = concentration_day_list_datetime\n",
    "    concentration_info_df.loc[:,['path']] = concentration_list\n",
    "    concentration_info_df = concentration_info_df.sort_values('date')\n",
    "    concentration_info_df.index = range(len(concentration_info_df))\n",
    "\n",
    "    con_emis_info_merged_df = pd.merge(concentration_info_df, emis_info_df, how='left', on='date', suffixes=['_concentration', '_emission'])\n",
    "        \n",
    "    con_emis_info_merged_df_dropna = con_emis_info_merged_df.loc[~con_emis_info_merged_df.path_emission.isna(),]\n",
    "    con_emis_info_merged_df_dropna.index = range(len(con_emis_info_merged_df_dropna))\n",
    "\n",
    "    writer_image = tf.io.TFRecordWriter(os.path.join(record_path,f\"dataset_{s_num}.tfr\"))\n",
    "    print(os.path.join(record_path,f\"dataset_{s_num}.tfr\"))\n",
    "\n",
    "    for k in range(len(con_emis_info_merged_df_dropna)):\n",
    "    # for i in range(len(con_emis_info_merged_df_dropna))[:1]:\n",
    "    \n",
    "        today = con_emis_info_merged_df_dropna.loc[k].date\n",
    "        print(today)\n",
    "        # 해당날짜의 데이터셋 불러오기\n",
    "        with xr.open_dataset(con_emis_info_merged_df_dropna.loc[k].path_concentration) as concen_data, xr.open_dataset(con_emis_info_merged_df_dropna.loc[k].path_emission) as emis_data:\n",
    "\n",
    "            pm10_chem_map = list(map(lambda chem: concen_data[chem], pm_10_chem_list))\n",
    "            smoke_chem_list = list(set(emis_data.variables.keys()) - set(['TFLAG']))\n",
    "            \n",
    "            smoke_chem_map = list(map(lambda chem: emis_data[chem][:,0,:,:], smoke_chem_list))\n",
    "\n",
    "            day_smoke_allval = np.moveaxis(np.array(smoke_chem_map), 0,3)\n",
    "            day_smoke_allval = day_smoke_allval[:24]\n",
    "\n",
    "            print('CMAQ_PM10 데이터셋: ',day_concen_pm10.shape, 'SMOKE_모든변수 데이터셋: ',day_smoke_allval.shape)\n",
    "\n",
    "            for hour_ind in range(24):\n",
    "            # for hour_ind in range(4):\n",
    "                datetime_ind = datetime.datetime(today.year, today.month, today.day, hour_ind)\n",
    "                print(str(datetime_ind))\n",
    "\n",
    "                air_pol_datetime_ind_df = air_pol_2013.loc[air_pol_2013.datetime == datetime_ind]\n",
    "                air_pol_datetime_ind_df.index = range(len(air_pol_datetime_ind_df))\n",
    "\n",
    "                air_pol_datetime_ind_df_geoinfo = pd.merge(air_pol_datetime_ind_df,site_info_dropna.loc[:,['stationName', 'geometry']],how='left',left_on='측정소명',right_on='stationName')\n",
    "                air_pol_datetime_ind_df_geoinfo = air_pol_datetime_ind_df_geoinfo.loc[~air_pol_datetime_ind_df_geoinfo.stationName.isna()]\n",
    "                air_pol_datetime_ind_df_geoinfo.index = range(len(air_pol_datetime_ind_df_geoinfo))\n",
    "                air_pol_datetime_ind_df_geoinfo = gpd.GeoDataFrame(air_pol_datetime_ind_df_geoinfo, geometry='geometry')\n",
    "                air_pol_datetime_ind_df_geoinfo = air_pol_datetime_ind_df_geoinfo.fillna(0)\n",
    "                air_pol_datetime_ind_df_geoinfo = air_pol_datetime_ind_df_geoinfo.loc[~(air_pol_datetime_ind_df_geoinfo.PM10 == -999)]  # 값이 -999찍혀있을때가 있음 기기오작동으로보고 제거\n",
    "                air_pol_datetime_ind_df_geoinfo.index = range(len(air_pol_datetime_ind_df_geoinfo))\n",
    "\n",
    "                # out_grid = make_geocube(vector_data=test_data, measurements=[\"습도(%)\"], geom=geom,resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "                out_grid = make_geocube(vector_data=air_pol_datetime_ind_df_geoinfo, measurements=[\"PM10\"],resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "                out_grid[\"PM10\"].rio.to_raster(os.path.join(record_path,\"rasterized_air_pol.tif\"))\n",
    "\n",
    "\n",
    "                dst_crs = projout\n",
    "                with rasterio.open(os.path.join(record_path,\"rasterized_air_pol.tif\")) as src:\n",
    "                    # print(src.width, src.height, *src.bounds,)\n",
    "                    transform, width, height = calculate_default_transform(\n",
    "                                    src.crs, \n",
    "                                    dst_crs, \n",
    "                                    src.width, \n",
    "                                    src.height, \n",
    "                                    *src.bounds)\n",
    "                \n",
    "                    kwargs = src.meta.copy()\n",
    "                    kwargs.update({\n",
    "                        'crs': dst_crs,\n",
    "                        'transform': transform,\n",
    "                        'width': width,\n",
    "                        'height': height\n",
    "                    })\n",
    "\n",
    "                    with rasterio.open(os.path.join(record_path,\"rasterized_air_pol_lcc.tif\"), 'w', **kwargs) as dst:\n",
    "                            \n",
    "                            for i in range(1, src.count + 1):\n",
    "                                reproject(\n",
    "                                    source=rasterio.band(src, i),\n",
    "                                    destination=rasterio.band(dst, i),\n",
    "                                    src_transform=src.transform,\n",
    "                                    src_crs=src.crs,\n",
    "                                    dst_transform=transform,\n",
    "                                    dst_crs=dst_crs,\n",
    "                                    resampling=Resampling.nearest)\n",
    "\n",
    "            \n",
    "\n",
    "                with rasterio.open(os.path.join(record_path,\"base_lcc_lcc.tif\")) as src, rasterio.open(os.path.join(record_path,\"rasterized_air_pol_lcc.tif\")) as src2:\n",
    "                    raster_list = [src, src2]\n",
    "                    # print(src.read(1).shape, src2.read(1).shape,)\n",
    "                    mosaic, output = merge(raster_list)\n",
    "\n",
    "                    output_meta = src2.meta.copy()\n",
    "                    output_meta.update(\n",
    "                        {\"driver\": \"GTiff\",\n",
    "                            \"height\": mosaic.shape[1],\n",
    "                            \"width\": mosaic.shape[2],\n",
    "                            \"transform\": output,\n",
    "                        }\n",
    "                    )\n",
    "\n",
    "                    with rasterio.open(os.path.join(record_path,\"rasterized_air_pol_lcc_final.tif\"), \"w\", **output_meta) as m:\n",
    "                        m.write(mosaic)\n",
    "\n",
    "                with rasterio.open(os.path.join(record_path,\"rasterized_air_pol_lcc_final.tif\")) as src:\n",
    "                    air_pol_pm10_arr = src.read(1)\n",
    "                    air_pol_pm10_arr = air_pol_pm10_arr.reshape(1,82,67,1)\n",
    "                    # print(air_pol_pm10_arr.shape)\n",
    "                em_df_ind_df = em_df.loc[em_df.datetime == datetime_ind]\n",
    "                em_df_ind_df.index = range(len(em_df_ind_df))\n",
    "                em_df_ind_df_geoinfo = pd.merge(em_df_ind_df,em_point_gdf.loc[:,['지점', 'geometry']],how='left',on = '지점')\n",
    "\n",
    "                em_df_ind_df_geoinfo = em_df_ind_df_geoinfo.loc[~em_df_ind_df_geoinfo.geometry.isna()]\n",
    "                em_df_ind_df_geoinfo.index = range(len(em_df_ind_df_geoinfo))\n",
    "                em_df_ind_df_geoinfo = gpd.GeoDataFrame(em_df_ind_df_geoinfo, geometry='geometry')\n",
    "                em_df_ind_df_geoinfo = em_df_ind_df_geoinfo.fillna(0)\n",
    "\n",
    "\n",
    "                out_grid = make_geocube(vector_data=em_df_ind_df_geoinfo, measurements=col_list,resolution=(9000, 9000), fill=0, output_crs=projout) #for most crs negative comes first in resolution\n",
    "                # out_grid[col_name].rio.to_raster(os.path.join(record_path,\"rasterized_em.tif\"))\n",
    "                out_grid.rio.to_raster(os.path.join(record_path,\"rasterized_em.tif\"))\n",
    "                with rasterio.open(os.path.join(record_path,\"rasterized_em.tif\")) as src:\n",
    "                        # print(src.count)\n",
    "                        transform, width, height = calculate_default_transform(\n",
    "                                        src.crs, \n",
    "                                        dst_crs, \n",
    "                                        src.width, \n",
    "                                        src.height, \n",
    "                                        *src.bounds)\n",
    "                    \n",
    "                        kwargs = src.meta.copy()\n",
    "                        kwargs.update({\n",
    "                            'crs': dst_crs,\n",
    "                            'transform': transform,\n",
    "                            'width': width,\n",
    "                            'height': height\n",
    "                        })\n",
    "\n",
    "                    \n",
    "\n",
    "                        with rasterio.open(os.path.join(record_path,\"rasterized_em_lcc.tif\"), 'w', **kwargs) as dst:\n",
    "\n",
    "                            for i in range(1, src.count + 1):\n",
    "                                \n",
    "                                reproject(\n",
    "                                    source=rasterio.band(src, i),\n",
    "                                    destination=rasterio.band(dst, i),\n",
    "                                    src_transform=src.transform,\n",
    "                                    src_crs=src.crs,\n",
    "                                    dst_transform=transform,\n",
    "                                    dst_crs=dst_crs,\n",
    "                                    resampling=Resampling.nearest)\n",
    "\n",
    "                with rasterio.open(os.path.join(record_path,f\"base_lcc_lcc_{band_depth}depth.tif\")) as src, rasterio.open(os.path.join(record_path,\"rasterized_em_lcc.tif\")) as src2:\n",
    "                        raster_list = [src, src2]\n",
    "                        # print(src.count, src2.count,)\n",
    "                        mosaic, output = merge(raster_list,)\n",
    "                        \n",
    "                        output_meta = src2.meta.copy()\n",
    "                        output_meta.update(\n",
    "                            {\"driver\": \"GTiff\",\n",
    "                                \"height\": mosaic.shape[1],\n",
    "                                \"width\": mosaic.shape[2],\n",
    "                                \"transform\": output,\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "                        with rasterio.open(os.path.join(record_path,\"rasterized_em_lcc_final.tif\"), \"w\", **output_meta) as m:\n",
    "                            m.write(mosaic)\n",
    "\n",
    "                \n",
    "                with rasterio.open(os.path.join(record_path,\"rasterized_em_lcc_final.tif\")) as src:\n",
    "\n",
    "                    em_arr_allband = src.read()\n",
    "                    em_arr_map = em_arr_allband.reshape(1,82,67,-1)\n",
    "\n",
    "                weather_t = em_arr_map[:1].tobytes()\n",
    "                air_q_t = air_pol_pm10_arr[:1].tobytes()\n",
    "                cmaq_t = day_concen_pm10[hour_ind:hour_ind+1].tobytes()\n",
    "                smoke_t = day_smoke_allval[hour_ind:hour_ind+1].tobytes()\n",
    "\n",
    "                example = tf.train.Example(\n",
    "                    features=tf.train.Features(\n",
    "                        feature={\n",
    "                            'CMAQ_t': _bytes_feature(cmaq_t),\n",
    "                            'SMOKE_t': _bytes_feature(smoke_t),\n",
    "                            'air_quality_monitoring_t': _bytes_feature(air_q_t),   \n",
    "                            'weather_monitoring_t': _bytes_feature(weather_t),\n",
    "                            'year': _bytes_feature(np.array(today.year - 2000).reshape(1,-1).tobytes()), \n",
    "                            'month': _bytes_feature(np.array(today.month).reshape(1,-1).tobytes()), \n",
    "                            'day': _bytes_feature(np.array(today.day).reshape(1,-1).tobytes()), \n",
    "                            'hour': _bytes_feature(np.array(hour_ind).reshape(1,-1).tobytes()), \n",
    "\n",
    "                        }\n",
    "                        )\n",
    "                    )\n",
    "                writer_image.write(example.SerializeToString())\n",
    "        \n",
    "    writer_image.close()\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    start_t = time.time()\n",
    "    print(i, time.time())\n",
    "    with Dataset(con_emis_info_merged_df_dropna.loc[k].path_concentration, 'r') as concen_data, Dataset(con_emis_info_merged_df_dropna.loc[k].path_emission, 'r') as emis_data:\n",
    "\n",
    "            # concen_data = Dataset(con_emis_info_merged_df_dropna.loc[k].path_concentration, 'r')\n",
    "            # emis_data = Dataset(con_emis_info_merged_df_dropna.loc[k].path_emission, 'r')\n",
    "\n",
    "            # 해당날짜의 관련변수 합으로 pm10 CMAQ array형성\n",
    "            pm10_chemlist = [np.array(concen_data.variables[chem]) for chem in pm_10_chem_list]\n",
    "            day_concen_pm10 = np.sum(pm10_chemlist, axis=0)\n",
    "            day_concen_pm10 = day_concen_pm10.reshape(day_concen_pm10.shape[0],day_concen_pm10.shape[2],day_concen_pm10.shape[3],-1)\n",
    "\n",
    "            # 해당날짜의 smoke 모든변수 array 형성, 연직방향으로는 맨 밑레이어만 사용\n",
    "            smoke_chem_list = list(set(emis_data.variables.keys()) - set(['TFLAG']))\n",
    "            # smoke_chem_arr_list = [np.array(emis_data.variables[chem])[:,0:1,:,:].reshape(25,82,67,-1) for chem in smoke_chem_list]\n",
    "            smoke_chem_arr_list = [emis_data[chem][:,0,:,:].reshape(25,82,67,-1) for chem in smoke_chem_list]\n",
    "    end_t = time.time()\n",
    "    print(end_t - start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conc_data = xr.open_dataset(merged_df.loc[i].path_concentration)\n",
    "emis_data = xr.open_dataset(merged_df.loc[i].path_emission)\n",
    "\n",
    "pm10_chem_map = map(lambda chem: conc_data[chem], pm_10_chem_list)\n",
    "smoke_chem_list = list(set(emis_data.variables.keys()) - set(['TFLAG']))\n",
    "print(time.time())\n",
    "smoke_chem_map = map(lambda chem: emis_data[chem], smoke_chem_list)\n",
    "print(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x7f8df3ee2910>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoke_chem_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in range(1000):\n",
    "    start_t = time.time()\n",
    "    print(i, time.time())\n",
    "    with xr.open_dataset(con_emis_info_merged_df_dropna.loc[k].path_concentration) as concen_data, xr.open_dataset(con_emis_info_merged_df_dropna.loc[k].path_emission) as emis_data:\n",
    "\n",
    "            # concen_data = Dataset(con_emis_info_merged_df_dropna.loc[k].path_concentration, 'r')\n",
    "            # emis_data = Dataset(con_emis_info_merged_df_dropna.loc[k].path_emission, 'r')\n",
    "\n",
    "            # # 해당날짜의 관련변수 합으로 pm10 CMAQ array형성\n",
    "            # pm10_chemlist = [np.array(concen_data.variables[chem]) for chem in pm_10_chem_list]\n",
    "            # day_concen_pm10 = np.sum(pm10_chemlist, axis=0)\n",
    "            # day_concen_pm10 = day_concen_pm10.reshape(day_concen_pm10.shape[0],day_concen_pm10.shape[2],day_concen_pm10.shape[3],-1)\n",
    "\n",
    "            # # 해당날짜의 smoke 모든변수 array 형성, 연직방향으로는 맨 밑레이어만 사용\n",
    "            # smoke_chem_list = list(set(emis_data.variables.keys()) - set(['TFLAG']))\n",
    "            # # smoke_chem_arr_list = [np.array(emis_data.variables[chem])[:,0:1,:,:].reshape(25,82,67,-1) for chem in smoke_chem_list]\n",
    "            # smoke_chem_arr_list = [emis_data[chem][:,0,:,:].reshape(25,82,67,-1) for chem in smoke_chem_list]\n",
    "\n",
    "            pm10_chem_map = list(map(lambda chem: concen_data[chem], pm_10_chem_list))\n",
    "            smoke_chem_list = list(set(emis_data.variables.keys()) - set(['TFLAG']))\n",
    "            \n",
    "            smoke_chem_map = list(map(lambda chem: emis_data[chem][:,0,:,:], smoke_chem_list))\n",
    "\n",
    "            np.array(smoke_chem_map).shape\n",
    "\n",
    "        np.moveaxis(np.array(smoke_chem_map), 0,3)\n",
    "            \n",
    "    end_t = time.time()\n",
    "    print(end_t - start_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 25, 82, 67)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(smoke_chem_map).shape\n",
    "\n",
    "np.moveaxis(np.array(smoke_chem_map), 0,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(np.moveaxis(np.array(smoke_chem_map), 0,3)[0,:,:,0] - np.array(smoke_chem_map)[0,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;PNO3&#x27; (TSTEP: 25, ROW: 82, COL: 67)&gt;\n",
       "array([[[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]]], dtype=float32)\n",
       "Dimensions without coordinates: TSTEP, ROW, COL\n",
       "Attributes:\n",
       "    long_name:  PNO3            \n",
       "    units:      g/s             \n",
       "    var_desc:   Model species PNO3                                           ...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'PNO3'</div><ul class='xr-dim-list'><li><span>TSTEP</span>: 25</li><li><span>ROW</span>: 82</li><li><span>COL</span>: 67</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-8d885b39-dd2b-4472-83f4-571b85431652' class='xr-array-in' type='checkbox' checked><label for='section-8d885b39-dd2b-4472-83f4-571b85431652' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0</span></div><div class='xr-array-data'><pre>array([[[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]]], dtype=float32)</pre></div></div></li><li class='xr-section-item'><input id='section-9575db96-d0ce-4d8e-b9b0-085989632444' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-9575db96-d0ce-4d8e-b9b0-085989632444' class='xr-section-summary'  title='Expand/collapse section'>Coordinates: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'></ul></div></li><li class='xr-section-item'><input id='section-15a9395e-d2fe-4b19-9ece-3fe09b847568' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-15a9395e-d2fe-4b19-9ece-3fe09b847568' class='xr-section-summary'  title='Expand/collapse section'>Indexes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'></ul></div></li><li class='xr-section-item'><input id='section-c9890748-ddfe-4591-a9bb-c9c5f7fb935c' class='xr-section-summary-in' type='checkbox'  checked><label for='section-c9890748-ddfe-4591-a9bb-c9c5f7fb935c' class='xr-section-summary' >Attributes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>PNO3            </dd><dt><span>units :</span></dt><dd>g/s             </dd><dt><span>var_desc :</span></dt><dd>Model species PNO3                                                              </dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'PNO3' (TSTEP: 25, ROW: 82, COL: 67)>\n",
       "array([[[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]]], dtype=float32)\n",
       "Dimensions without coordinates: TSTEP, ROW, COL\n",
       "Attributes:\n",
       "    long_name:  PNO3            \n",
       "    units:      g/s             \n",
       "    var_desc:   Model species PNO3                                           ..."
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smoke_chem_map[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 20px 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;PNO3&#x27; (TSTEP: 25, ROW: 82, COL: 67)&gt;\n",
       "array([[[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]]], dtype=float32)\n",
       "Dimensions without coordinates: TSTEP, ROW, COL\n",
       "Attributes:\n",
       "    long_name:  PNO3            \n",
       "    units:      g/s             \n",
       "    var_desc:   Model species PNO3                                           ...</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'PNO3'</div><ul class='xr-dim-list'><li><span>TSTEP</span>: 25</li><li><span>ROW</span>: 82</li><li><span>COL</span>: 67</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-66992f7c-ff69-4a23-99b2-26e97aec6991' class='xr-array-in' type='checkbox' checked><label for='section-66992f7c-ff69-4a23-99b2-26e97aec6991' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0</span></div><div class='xr-array-data'><pre>array([[[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]]], dtype=float32)</pre></div></div></li><li class='xr-section-item'><input id='section-a200eea2-380b-4aff-be6e-4bc18e97d5d6' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-a200eea2-380b-4aff-be6e-4bc18e97d5d6' class='xr-section-summary'  title='Expand/collapse section'>Coordinates: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'></ul></div></li><li class='xr-section-item'><input id='section-1338ebcd-6e8c-4e4e-a566-3977de84e856' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-1338ebcd-6e8c-4e4e-a566-3977de84e856' class='xr-section-summary'  title='Expand/collapse section'>Indexes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'></ul></div></li><li class='xr-section-item'><input id='section-f62bf076-d5d9-4fb6-bae9-8d0dabff6c8d' class='xr-section-summary-in' type='checkbox'  checked><label for='section-f62bf076-d5d9-4fb6-bae9-8d0dabff6c8d' class='xr-section-summary' >Attributes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'><dt><span>long_name :</span></dt><dd>PNO3            </dd><dt><span>units :</span></dt><dd>g/s             </dd><dt><span>var_desc :</span></dt><dd>Model species PNO3                                                              </dd></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'PNO3' (TSTEP: 25, ROW: 82, COL: 67)>\n",
       "array([[[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]],\n",
       "\n",
       "       [[0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., ..., 0., 0.],\n",
       "        [0., 0., ..., 0., 0.]]], dtype=float32)\n",
       "Dimensions without coordinates: TSTEP, ROW, COL\n",
       "Attributes:\n",
       "    long_name:  PNO3            \n",
       "    units:      g/s             \n",
       "    var_desc:   Model species PNO3                                           ..."
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emis_data[chem][:,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5b3ded1ccb95c1d9bd405e7b823d9e85424cde40fbb5985eb47e999ef50e15b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
